{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a873753e-abc9-4f09-abc8-6db4d04daaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Pytorch & other libraries\n",
    "%pip install \"torch==2.4.0\" tensorboard pillow\n",
    "\n",
    "# Install Hugging Face libraries\n",
    "%pip install  --upgrade \\\n",
    "  \"transformers==4.45.1\" \\\n",
    "  \"datasets==3.0.1\" \\\n",
    "  \"accelerate==0.34.2\" \\\n",
    "  \"evaluate==0.4.3\" \\\n",
    "  \"bitsandbytes==0.44.0\" \\\n",
    "  \"trl==0.11.1\" \\\n",
    "  \"peft==0.13.0\" \\\n",
    "  \"qwen-vl-utils\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06152950-8f2d-424b-8feb-10e64af64188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ninja\n",
      "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (23.2)\n",
      "Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ninja\n",
      "Successfully installed ninja-1.11.1.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting flash-attn\n",
      "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.4.0)\n",
      "Collecting einops (from flash-attn)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp310-cp310-linux_x86_64.whl size=187788763 sha256=a8719a86d0cd12a105739151f9e45ac8c2ecb840a83ed7a080a88d1645a98440\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/ce/d5/08ea07bfc16ba218dc65a3a7ef9b6a270530bcbd2cea2ee1ca\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: einops, flash-attn\n",
      "Successfully installed einops-0.8.1 flash-attn-2.7.4.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# GPU가 Flash Attention을 지원하는지 확인\n",
    "assert torch.cuda.get_device_capability()[0] >= 8, 'Hardware not supported for Flash Attention'\n",
    "\n",
    "# Flash Attention 설치\n",
    "!pip install ninja packaging\n",
    "!pip install flash-attn --no-build-isolation --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ba181b-6645-4751-b6f2-1a7b0c47b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import streamlit as st\n",
    "import pandas as pd\n",
    "# import fitz\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "import praw\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91f49c30-5247-4989-8fa6-35b02bfd955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc8d9f3f-a47c-42c0-a43d-446d572bf42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/final_train_messages.pkl' ,'rb' )as f:\n",
    "    final_train_messages =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "073a3f2a-88d2-45b6-862f-9289ee5ab961",
   "metadata": {},
   "outputs": [],
   "source": [
    "messeges = [{'message':d} for d in final_train_messages]\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_list(messeges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59acfbd2-5a95-4584-bb4e-7f93b8b8aeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686289252db549f4b434f1d2954e7440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634404ec5f5f45a2b0d71a92736f49a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/47.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be0ff72753049b1877906df7db5a75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93dde8c573bb4796b62e1a08771209e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00008.safetensors:   0%|          | 0.00/3.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f34e5a0f94a4e70a42426bdadee43f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b6667cecac4cae8b80c13e77cbf8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e50c4c8924849a6a1075fd0d87ce09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7503a780045042cb99d1dd6fc05bda9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00008.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979643b13033417bb6415c25a8d31894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea70bb36c8d64b6997495e10402e3b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf4fd8c09d342a0881e94933cb49088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00008.safetensors:   0%|          | 0.00/1.70G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1070cbf7918a44859298bfa530924aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc07630e2ed4ea4afb89030353b8b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1ba292f6f84c0cadcea418d48ce121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11fe0cf1d6747c18e83cb96bfe28886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fe497f1102496dba983c79365b740d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c35ece3514f49c2a735d8b8ffd26c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# 허깅페이스 모델 ID\n",
    "model_id = \"Qwen/Qwen2.5-14B-Instruct\" \n",
    "\n",
    "# BitsAndBytes 4비트 양자화 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,                             # 4비트 양자화 사용\n",
    "   bnb_4bit_use_double_quant=True,               # 이중 양자화 사용으로 메모리 추가 절약\n",
    "   bnb_4bit_quant_type=\"nf4\",                    # 4비트 양자화 타입 설정(normalized float 4)\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16         # 연산 시 bfloat16 타입 사용\n",
    ")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ad7c061-c80d-4af2-9928-07a8123e1ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "당신은 다양한 기능을 호출할 수 있는 AI 모델입니다. 사용자의 요청에 따라 특정 함수를 호출하며, 각 함수의 사용 방법과 파라미터는 <tools></tools> XML 태그 안에 명시되어 있습니다. 함수를 호출할 때는 사용자가 제공한 값에 따라 정확히 실행해야 합니다.\n",
      "\n",
      "사용 가능한 함수와 각 파라미터의 설명은 다음과 같습니다:\n",
      "\n",
      "1. get_issues_summarized\n",
      "   - 설명: 특정 회사나 키워드에 대한 이슈를 검색하고 요약합니다.\n",
      "   - 파라미터:\n",
      "     - keyword: 검색하고자 하는 회사명 또는 키워드.\n",
      "     - days: 검색 기간(일 단위).\n",
      "\n",
      "2. get_reddit_hotissue\n",
      "   - 설명: 금융 시장에서 현재 주목받고 있는 이슈를 요약합니다.\n",
      "   - 파라미터:\n",
      "     - days: 검색 기간(일 단위).\n",
      "\n",
      "3. get_earnings\n",
      "   - 설명: 기업의 재무재표나 현금흐름을 가져오고 분석합니다. 이전 년도 데이터가 필요한 경우, 해당 데이터를 추가로 호출합니다.\n",
      "           함수 호출 시 연도와 분기 설정에 주의해야 합니다. 보통 1분기 실적발표는 4월 중순 ~ 5월 초, 2분기는 7월 중순 ~ 8월초, 3분기는 10월중순~ 11월 초, \n",
      "            4분기는 1월 중순 ~2월초에 발표 된다. \n",
      "            ## 예시: 1. 오늘 날짜 2025년 2월 18일 , 최근 실적발표의 year  과 quarter 은?\n",
      "            year : '2024' , quarter: -1 또는, 4 \n",
      "   - 파라미터:\n",
      "     - symbol: 데이터를 검색하고자 하는 기업 심볼.\n",
      "     - analysis_type: 분석 유형(growth, profitability, stability, valuation, cashflow, dividend, cost, NA).\n",
      "     - type_: 데이터 타입(yearly 또는 quarter).\n",
      "     - year: 데이터를 검색하고자 하는 연도(명시하지 않으면 최근 연도 데이터 참조).\n",
      "     - quarter: 데이터를 검색하고자 하는 분기(명시하지 않으면 -1을 입력하여 최근 데이터 조회).\n",
      "\n",
      "4. get_consensus\n",
      "   - 설명: 기업의 EPS 컨센서스 데이터 또는 매수/매도/홀드 의견을 분석합니다. \n",
      "     함수 호출 시 연도와 분기 설정에 주의해야 합니다. 컨센서스는 1분기 3월 말 ~ 4월 초, 2분기 6월 말 ~ 7월 초, 3분기는 9월 말 ~ 10월 초, 4분기는 12월 말 ~ 1월초 에 발표된다.\n",
      "     ## 예시: 1. 오늘 날짜 2025년 4월 18일 , 최근 컨센서스의 year 과 quarter 은?\n",
      "            year : '2025' , quarter: 1 또는, -1\n",
      "   - 파라미터:\n",
      "     - symbol: 데이터를 검색하고자 하는 기업 심볼.\n",
      "     - year: 데이터를 검색하고자 하는 연도.\n",
      "     - quarter: 데이터를 검색하고자 하는 분기.\n",
      "\n",
      "함수를 호출할 때는 아래 예시와 같이 <tool_call></tool_call> XML 태그 안에 JSON 객체를 사용하여 함수 이름과 인자들을 명시합니다:\n",
      "\n",
      "<tool_call>\n",
      "{\n",
      "    \"name\": \"get_earnings\",\n",
      "    \"arguments\": {\n",
      "        \"symbol\": \"AAPL\",\n",
      "        \"analysis_type\": \"growth\",\n",
      "        \"type_\": \"yearly\",\n",
      "        \"year\": \"2024\",\n",
      "        \"quarter\": \"-1\"\n",
      "    }\n",
      "}\n",
      "</tool_call>\n",
      "\n",
      "\n",
      "\n",
      "**주의사항\n",
      "함수를 호출할 때를 제외하고는 모든 응답을 한국어로 제공해야 합니다.\n",
      "오늘 날짜는 2022년 04월 03일 입니다.<|im_end|>\n",
      "<|im_start|>user\n",
      "금융시장에서 최근 일주일간의 주요 이슈는 무엇인가요?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>{\"name\":\"get_reddit_hotissue\",\"arguments\": {\"days\": 7}}</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "<tool_reponse>title :What Are Your Moves Tomorrow, March 20, 2025\n",
      "body :This post contains content not supported on old Reddit. [Click here to view the full post](https://sh.reddit.com/r/wallstreetbets/comments/1jf65ux)\n",
      "\n",
      "title :Tesla (TSLA) accounting raises red flags as report shows $1.4 billion missing\n",
      "body :\n",
      "\n",
      "title :Every single FED’s conference should look like this\n",
      "body :\n",
      "\n",
      "title :Trump still intends for reciprocal tariffs to kick in on April 2, White House says\n",
      "body :Summary\n",
      "\n",
      "* White House official says tariffs to take effect April 2\n",
      "* Negotiations to lower tariffs needed ahead of April 2Countries to get tariff number on April 2, Bessent says\n",
      "* Bessent sees opportunity to negotiate tariffs lower\n",
      "* USTR wrestling with design of complex reciprocal tariff plan\n",
      "\n",
      "WASHINGTON, March 18 (Reuters) - U.S. President [Donald Trump](https://www.reuters.com/world/us/donald-trump/) still intends for new reciprocal tariff rates to take effect on April 2, the White House said on Tuesday, despite earlier comments from Treasury Secretary Scott Bessent that indicated a possible delay in their activation.\"The intent is to enact tariffs on April 2,\" the official said when asked to clarify Bessent's comments that countries would get an opportunity to avoid higher tariffs by reducing their own trade barriers.\n",
      "\n",
      "Get weekly news and analysis on U.S. politics and how it matters to the world with the Reuters Politics U.S. newsletter. Sign up [here.](https://www.reuters.com/newsletters/reuters-politics-us/?location=article-paragraph)\n",
      "\n",
      "\"Unless the tariff and non-tariff barriers are equalized, or the U.S. has higher tariffs, the tariffs will go into effect,\" the White House official said.Bessent told Fox Business Network's \"Mornings with Maria\" program that Trump on April 2 would give trading partner countries a [reciprocal tariff](https://www.reuters.com/world/us/trump-says-reciprocal-tariffs-coming-thursday-2025-02-13/) number that reflects their own rates, non-tariff trade barriers, currency practice and other factors, but could negotiate to avoid a \"tariff wall.\"\"On April 2, each country will receive a number that we believe represents their tariffs,\" Bessent said. \"For some countries, it could be quite low, for some countries, it could be quite high.\"\"We are going to go to them and say, 'Look, here's where we think the tariff levels are, non-tariff barriers, currency manipulation, unfair funding, labor suppression, and if you will stop this, we will not put up the tariff wall,'\" Bessent said</tool_response><|im_end|>\n",
      "<|im_start|>assistant\n",
      "최근 일주일간 금융시장에서 주목받고 있는 주요 이슈는 다음과 같습니다:\n",
      "\n",
      "1. **Tesla (TSLA)의 회계 문제**: Tesla의 회계에서 1.4억 달러가 사라졌다는 보고서가 나오면서 경고 신호가 제기되었습니다.\n",
      "\n",
      "2. **트럼프 대통령의 상호 관세 정책**: 백악관은 4월 2일에 새로운 상호 관세율이 시행될 것이라고 밝혔습니다. 이에 따라 각국은 그들의 관세 및 비관세 장벽을 낮추기 위한 협상이 필요할 것으로 보입니다. 미국 통상대표부(USTR)는 복잡한 상호 관세 계획의 디자인을 두고 씨름 중입니다. \n",
      "\n",
      "다른 이슈로는 연준의 회의에 대한 관심과 구체적인 내용은 제공되지 않았습니다.\n",
      "\n",
      "이슈들은 금융 및 정치적 요소들로 구성되어 있으며, 특히 Tesla의 회계 문제와 트럼프 대통령의 상호 관세 발표가 주목받고 있습니다.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 적용\n",
    "text = tokenizer.apply_chat_template(\n",
    "    dataset[0][\"message\"], tokenize=False, add_generation_prompt=False\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c7e00b1-bba5-461f-8c02-f6c0cdade7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    " \n",
    "# QLoRA 논문 및 Sebastian Raschka 실험에 기반한 LoRA Conifg\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0,\n",
    "        r=16,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "\n",
    "# from transformers import TrainingArguments\n",
    "from trl import SFTConfig\n",
    "\n",
    "args = SFTConfig(\n",
    "    output_dir=\"qwen2.5-14b-functioncall\",     # 저장될 디렉토리와 저장소 ID\n",
    "    num_train_epochs=10,                      # 학습할 총 에포크 수\n",
    "    per_device_train_batch_size=8,           # 장치당 학습 배치 크기\n",
    "    gradient_accumulation_steps=2,           # 역전파/가중치 업데이트 전 누적할 스텝 수\n",
    "    gradient_checkpointing=True,             # 메모리 절약을 위한 그래디언트 체크포인팅 사용\n",
    "    optim=\"adamw_torch_fused\",               # 퓨즈드 AdamW 옵티마이저 사용\n",
    "    logging_steps=10,                        # 10스텝마다 로그 기록\n",
    "    save_strategy=\"steps\",                   # 특정 스텝마다 체크포인트 저장\n",
    "    save_steps=50,\n",
    "    bf16=True,                              # bfloat16 정밀도 사용\n",
    "    tf32=True,                              # tf32 정밀도 사용\n",
    "    learning_rate=1e-4,                     # 학습률 (QLoRA 논문 기반)\n",
    "    max_grad_norm=0.3,                      # 최대 그래디언트 노름 (QLoRA 논문 기반)\n",
    "    warmup_ratio=0.03,                      # 워밍업 비율 (QLoRA 논문 기반)\n",
    "    lr_scheduler_type=\"constant\",           # 고정 학습률 스케줄러 사용\n",
    "    push_to_hub=False,                      # 허브에 모델 업로드 안 함\n",
    "    report_to=\"tensorboard\",                # 텐서보드에 메트릭 기록\n",
    "    remove_unused_columns=False,\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48e9b88b-9e13-41d4-a2f3-0d64fee8b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    new_batch = {\n",
    "        \"input_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "    \n",
    "    for example in batch:\n",
    "        # messages의 각 내용에서 개행문자 제거\n",
    "        clean_messages = []\n",
    "        for message in example[\"message\"]:\n",
    "            clean_message = {\n",
    "                \"role\": message[\"role\"],\n",
    "                \"content\": message[\"content\"]\n",
    "            }\n",
    "            clean_messages.append(clean_message)\n",
    "        \n",
    "        # 깨끗해진 메시지로 템플릿 적용\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            clean_messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        ).strip()\n",
    "        \n",
    "        # 텍스트를 토큰화\n",
    "        tokenized = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=max_seq_length,\n",
    "            padding=False,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        \n",
    "        input_ids = tokenized[\"input_ids\"]\n",
    "        attention_mask = tokenized[\"attention_mask\"]\n",
    "        \n",
    "        # 레이블 초기화\n",
    "        labels = [-100] * len(input_ids)\n",
    "        \n",
    "        # assistant 응답 부분 찾기\n",
    "        im_start = \"<|im_start|>\"\n",
    "        im_end = \"<|im_end|>\"\n",
    "        assistant = \"assistant\"\n",
    "        \n",
    "        # 토큰 ID 가져오기\n",
    "        im_start_tokens = tokenizer.encode(im_start, add_special_tokens=False)\n",
    "        im_end_tokens = tokenizer.encode(im_end, add_special_tokens=False)\n",
    "        assistant_tokens = tokenizer.encode(assistant, add_special_tokens=False)\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(input_ids):\n",
    "            # <|im_start|>assistant 찾기\n",
    "            if (i + len(im_start_tokens) <= len(input_ids) and \n",
    "                input_ids[i:i+len(im_start_tokens)] == im_start_tokens):\n",
    "                \n",
    "                # assistant 토큰 찾기\n",
    "                assistant_pos = i + len(im_start_tokens)\n",
    "                if (assistant_pos + len(assistant_tokens) <= len(input_ids) and \n",
    "                    input_ids[assistant_pos:assistant_pos+len(assistant_tokens)] == assistant_tokens):\n",
    "                    \n",
    "                    # assistant 응답의 시작 위치로 이동\n",
    "                    current_pos = assistant_pos + len(assistant_tokens)\n",
    "                    \n",
    "                    # <|im_end|>를 찾을 때까지 레이블 설정\n",
    "                    while current_pos < len(input_ids):\n",
    "                        if (current_pos + len(im_end_tokens) <= len(input_ids) and \n",
    "                            input_ids[current_pos:current_pos+len(im_end_tokens)] == im_end_tokens):\n",
    "                            # <|im_end|> 토큰도 레이블에 포함\n",
    "                            for j in range(len(im_end_tokens)):\n",
    "                                labels[current_pos + j] = input_ids[current_pos + j]\n",
    "                            break\n",
    "                        labels[current_pos] = input_ids[current_pos]\n",
    "                        current_pos += 1\n",
    "                    \n",
    "                    i = current_pos\n",
    "                \n",
    "            i += 1\n",
    "        \n",
    "        new_batch[\"input_ids\"].append(input_ids)\n",
    "        new_batch[\"attention_mask\"].append(attention_mask)\n",
    "        new_batch[\"labels\"].append(labels)\n",
    "    \n",
    "    # 패딩 적용\n",
    "    max_length = max(len(ids) for ids in new_batch[\"input_ids\"])\n",
    "    \n",
    "    for i in range(len(new_batch[\"input_ids\"])):\n",
    "        padding_length = max_length - len(new_batch[\"input_ids\"][i])\n",
    "        \n",
    "        new_batch[\"input_ids\"][i].extend([tokenizer.pad_token_id] * padding_length)\n",
    "        new_batch[\"attention_mask\"][i].extend([0] * padding_length)\n",
    "        new_batch[\"labels\"][i].extend([-100] * padding_length)\n",
    "    \n",
    "    # 텐서로 변환\n",
    "    for k, v in new_batch.items():\n",
    "        new_batch[k] = torch.tensor(v)\n",
    "    \n",
    "    return new_batch\n",
    "\n",
    "def print_tokens_and_labels(batch):\n",
    "    input_ids = batch[\"input_ids\"][0].tolist()\n",
    "    labels = batch[\"labels\"][0].tolist()\n",
    "    \n",
    "    print(\"\\n토큰과 레이블 비교:\")\n",
    "    print(f\"{'Token ID':<10} {'Token':<30} {'Label':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for token_id, label in zip(input_ids, labels):\n",
    "        token = tokenizer.decode([token_id])\n",
    "        label_str = str(label) if label != -100 else \"-100\"\n",
    "        print(f\"{token_id:<10} {token:<30} {label_str:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "969abf00-6699-4857-bbdc-a915a09fd10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9052ef78-1f4a-4b0d-8953-1e6c67c69658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "처리된 배치 데이터:\n",
      "입력 ID 형태: torch.Size([1, 1818])\n",
      "어텐션 마스크 형태: torch.Size([1, 1818])\n",
      "레이블 형태: torch.Size([1, 1818])\n"
     ]
    }
   ],
   "source": [
    "# collate_fn 테스트 (배치 크기 1로)\n",
    "max_seq_length = 8192  \n",
    "batch = collate_fn([example])\n",
    "print(\"\\n처리된 배치 데이터:\")\n",
    "print(\"입력 ID 형태:\", batch[\"input_ids\"].shape)\n",
    "print(\"어텐션 마스크 형태:\", batch[\"attention_mask\"].shape)\n",
    "print(\"레이블 형태:\", batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f57fb9d9-39d6-4860-a1eb-dbdd4dcec234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력에 대한 정수 인코딩 결과:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 198, 151657, 4913, 606, 3252, 455, 1288, 20090, 33433, 11159, 2198, 16370, 788, 5212, 13778, 788, 220, 22, 3417, 151658, 151645, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 198, 128215, 125722, 83556, 54330, 32077, 62275, 40771, 230, 128024, 133627, 56475, 55673, 87608, 132872, 34395, 64521, 55673, 35711, 23084, 144018, 16560, 139107, 138691, 1447, 16, 13, 3070, 89441, 320, 51, 7984, 32, 8, 20401, 98005, 124781, 126674, 95518, 27199, 20401, 98005, 124781, 56475, 220, 16, 13, 19, 127475, 34143, 105, 60294, 19969, 32129, 50340, 128036, 130822, 63332, 34395, 26698, 19969, 137298, 131611, 43115, 34395, 128753, 47324, 19969, 62071, 20487, 141167, 382, 17, 13, 3070, 28626, 125894, 126445, 136774, 20401, 58034, 47324, 92751, 41429, 36055, 126712, 95518, 22042, 109, 131893, 124780, 33704, 220, 19, 128514, 220, 17, 32077, 19391, 134585, 58034, 47324, 92751, 41429, 132841, 12802, 138767, 131396, 71108, 130939, 22042, 251, 144472, 38231, 13, 23084, 19391, 126629, 126804, 124785, 33704, 54825, 129360, 92751, 41429, 128355, 73986, 124780, 41429, 129359, 141479, 17877, 37195, 106, 132526, 20487, 130679, 47455, 239, 55902, 12802, 126871, 47836, 132091, 63332, 78952, 13, 132662, 125206, 55902, 66845, 126414, 63089, 12317, 6666, 8, 16560, 30520, 113, 132499, 23573, 58034, 47324, 92751, 41429, 94203, 127324, 20401, 76497, 242, 25715, 31328, 17877, 129419, 34395, 3315, 242, 101, 63154, 70943, 78952, 13, 4710, 13146, 82965, 23084, 144018, 17380, 16560, 77353, 129044, 20401, 98005, 20401, 19391, 128605, 138449, 53680, 58777, 49543, 128533, 130213, 33704, 130094, 132553, 133995, 38231, 382, 12802, 144018, 128901, 40771, 230, 128024, 128355, 136994, 80968, 85997, 43590, 64850, 17380, 136239, 128993, 132931, 11, 136115, 27199, 20401, 98005, 124781, 126674, 80573, 127819, 116, 125894, 126445, 136774, 20401, 58034, 47324, 92751, 41429, 142234, 19969, 55673, 87608, 132872, 34395, 128472, 13, 151645]\n"
     ]
    }
   ],
   "source": [
    "print('입력에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"labels\"][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f439f18e-d11e-4b58-bc51-520692704937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "max_seq_length = 8192  # 모델과 데이터셋 패킹을 위한 최대 시퀀스 길이\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    max_seq_length=max_seq_length,  # 최대 시퀀스 길이 설정\n",
    "    train_dataset=dataset,\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5785dc1-9364-4c62-aefe-699dce47d146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='1110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  42/1110 17:16 < 7:41:15, 0.04 it/s, Epoch 0.37/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.791900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.669800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.565100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.589300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 시작\n",
    "trainer.train()   # 모델이 자동으로 허브와 output_dir에 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a3fd72-a1aa-46c3-8764-b51a06e9b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
