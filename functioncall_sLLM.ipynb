{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f2d4cf-3f0e-4c92-b6fb-29b9f1dc6830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.4.0\n",
      "  Using cached torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2023.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (10.3.2.106)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.8.93)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.2.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.24.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (6.30.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "Using cached torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Installing collected packages: nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu118\n",
      "    Uninstalling torch-2.1.0+cu118:\n",
      "      Successfully uninstalled torch-2.1.0+cu118\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.4.0 which is incompatible.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cudnn-cu12-9.1.0.70 nvidia-cusolver-cu12-11.4.5.107 torch-2.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting transformers==4.45.1\n",
      "  Using cached transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting datasets==3.0.1\n",
      "  Using cached datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting accelerate==0.34.2\n",
      "  Using cached accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate==0.4.3\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting bitsandbytes==0.44.0\n",
      "  Using cached bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting trl==0.11.1\n",
      "  Using cached trl-0.11.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting peft==0.13.0\n",
      "  Using cached peft-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting qwen-vl-utils\n",
      "  Using cached qwen_vl_utils-0.0.10-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers==4.45.1)\n",
      "  Using cached huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.45.1)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (2.31.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.45.1)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers==4.45.1)\n",
      "  Using cached tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.45.1)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets==3.0.1)\n",
      "  Using cached pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.0.1)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting requests (from transformers==4.45.1)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from datasets==3.0.1)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets==3.0.1)\n",
      "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==3.0.1) (2023.4.0)\n",
      "Collecting aiohttp (from datasets==3.0.1)\n",
      "  Downloading aiohttp-3.11.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (5.9.6)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (2.4.0)\n",
      "Collecting tyro>=0.5.11 (from trl==0.11.1)\n",
      "  Downloading tyro-0.9.17-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting av (from qwen-vl-utils)\n",
      "  Downloading av-14.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from qwen-vl-utils) (9.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets==3.0.1)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets==3.0.1)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets==3.0.1)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets==3.0.1)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==3.0.1)\n",
      "  Downloading multidict-6.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets==3.0.1)\n",
      "  Downloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets==3.0.1)\n",
      "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers==4.45.1)\n",
      "  Downloading huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.29.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is still looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.0-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.4-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.23.5-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting fsspec[http]<=2024.6.1,>=2023.1.0 (from datasets==3.0.1)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.1) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (2022.12.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.34.2) (12.8.93)\n",
      "Collecting docstring-parser>=0.15 (from tyro>=0.5.11->trl==0.11.1)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rich>=11.1.0 (from tyro>=0.5.11->trl==0.11.1)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.11.1)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro>=0.5.11->trl==0.11.1)\n",
      "  Downloading typeguard-4.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==3.0.1)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.1)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.1) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.34.2) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.34.2) (1.3.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.11.1)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m184.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.11.1-py3-none-any.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.4/318.4 kB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.13.0-py3-none-any.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading qwen_vl_utils-0.0.10-py3-none-any.whl (6.7 kB)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m192.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m171.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m144.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 kB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m144.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m168.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.9.17-py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.7/123.7 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading av-14.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m140.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.4/205.4 kB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
      "Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, typeguard, tqdm, shtab, safetensors, requests, regex, pyarrow, propcache, multidict, mdurl, fsspec, frozenlist, docstring-parser, dill, av, async-timeout, aiohappyeyeballs, yarl, qwen-vl-utils, pandas, multiprocess, markdown-it-py, huggingface-hub, aiosignal, tokenizers, rich, aiohttp, tyro, transformers, bitsandbytes, accelerate, peft, datasets, trl, evaluate\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.4.0 which is incompatible.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.34.2 aiohappyeyeballs-2.6.1 aiohttp-3.11.14 aiosignal-1.3.2 async-timeout-5.0.1 av-14.2.0 bitsandbytes-0.44.0 datasets-3.0.1 dill-0.3.8 docstring-parser-0.16 evaluate-0.4.3 frozenlist-1.5.0 fsspec-2024.6.1 huggingface-hub-0.29.3 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.2.0 multiprocess-0.70.16 pandas-2.2.3 peft-0.13.0 propcache-0.3.0 pyarrow-19.0.1 pytz-2025.1 qwen-vl-utils-0.0.10 regex-2024.11.6 requests-2.32.3 rich-13.9.4 safetensors-0.5.3 shtab-1.7.1 tokenizers-0.20.3 tqdm-4.67.1 transformers-4.45.1 trl-0.11.1 typeguard-4.4.2 tyro-0.9.17 tzdata-2025.2 xxhash-3.5.0 yarl-1.18.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install Pytorch & other libraries\n",
    "%pip install \"torch==2.4.0\" tensorboard pillow\n",
    "\n",
    "# Install Hugging Face libraries\n",
    "%pip install  --upgrade \\\n",
    "  \"transformers==4.45.1\" \\\n",
    "  \"datasets==3.0.1\" \\\n",
    "  \"accelerate==0.34.2\" \\\n",
    "  \"evaluate==0.4.3\" \\\n",
    "  \"bitsandbytes==0.44.0\" \\\n",
    "  \"trl==0.11.1\" \\\n",
    "  \"peft==0.13.0\" \\\n",
    "  \"qwen-vl-utils\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5439df-7fd1-4e51-b400-a1df4c4cc0af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vllm==0.6.0 (from -r requirements.txt (line 1))\n",
      "  Downloading vllm-0.6.0-cp38-abi3-manylinux1_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 2))\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting fitz (from -r requirements.txt (line 3))\n",
      "  Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl.metadata (816 bytes)\n",
      "Collecting PyMuPDF (from -r requirements.txt (line 4))\n",
      "  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting praw (from -r requirements.txt (line 5))\n",
      "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting yfinance (from -r requirements.txt (line 6))\n",
      "  Downloading yfinance-0.2.55-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting streamlit (from -r requirements.txt (line 7))\n",
      "  Downloading streamlit-1.43.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (5.9.6)\n",
      "Collecting sentencepiece (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (1.24.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (4.67.1)\n",
      "Collecting py-cpuinfo (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: transformers>=4.43.2 in /usr/local/lib/python3.10/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (4.45.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (0.20.3)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (6.30.1)\n",
      "Collecting fastapi (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (3.11.14)\n",
      "Collecting openai>=1.0 (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading openai-1.68.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn[standard] (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pydantic>=2.8 (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (9.3.0)\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (0.18.0)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken>=0.6.0 (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting lm-format-enforcer==0.10.6 (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading lm_format_enforcer-0.10.6-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting outlines<0.1,>=0.0.43 (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading outlines-0.0.46-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (4.12.2)\n",
      "Collecting filelock>=3.10.4 (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting partial-json-parser (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (24.0.1)\n",
      "Collecting msgspec (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting gguf==0.9.1 (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading gguf-0.9.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (4.6.4)\n",
      "Collecting mistral-common>=1.3.4 (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading mistral_common-1.5.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (6.0.1)\n",
      "Collecting ray>=2.9 (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading ray-2.44.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting nvidia-ml-py (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from vllm==0.6.0->-r requirements.txt (line 1)) (2.4.0)\n",
      "Collecting torchvision==0.19 (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "Collecting xformers==0.0.27.post2 (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting vllm-flash-attn==2.6.1 (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading vllm_flash_attn-2.6.1-cp310-cp310-manylinux1_x86_64.whl.metadata (476 bytes)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.10.6->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer==0.10.6->vllm==0.6.0->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (12.8.93)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn->-r requirements.txt (line 2))\n",
      "  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 2))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->-r requirements.txt (line 2))\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting configobj (from fitz->-r requirements.txt (line 3))\n",
      "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting configparser (from fitz->-r requirements.txt (line 3))\n",
      "  Downloading configparser-7.2.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: httplib2 in /usr/lib/python3/dist-packages (from fitz->-r requirements.txt (line 3)) (0.20.2)\n",
      "Collecting nibabel (from fitz->-r requirements.txt (line 3))\n",
      "  Downloading nibabel-5.3.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting nipype (from fitz->-r requirements.txt (line 3))\n",
      "  Downloading nipype-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz->-r requirements.txt (line 3)) (2.2.3)\n",
      "Collecting pyxnat (from fitz->-r requirements.txt (line 3))\n",
      "  Downloading pyxnat-1.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting prawcore<3,>=2.4 (from praw->-r requirements.txt (line 5))\n",
      "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting update_checker>=0.18 (from praw->-r requirements.txt (line 5))\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw->-r requirements.txt (line 5)) (1.6.4)\n",
      "Collecting multitasking>=0.0.7 (from yfinance->-r requirements.txt (line 6))\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 6)) (3.11.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 6)) (2025.1)\n",
      "Collecting frozendict>=2.3.4 (from yfinance->-r requirements.txt (line 6))\n",
      "  Downloading frozendict-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance->-r requirements.txt (line 6))\n",
      "  Downloading peewee-3.17.9.tar.gz (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m192.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 6)) (4.12.2)\n",
      "Collecting altair<6,>=4.0 (from streamlit->-r requirements.txt (line 7))\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit->-r requirements.txt (line 7)) (1.4)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit->-r requirements.txt (line 7))\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit->-r requirements.txt (line 7))\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (19.0.1)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit->-r requirements.txt (line 7))\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit->-r requirements.txt (line 7))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit->-r requirements.txt (line 7))\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit->-r requirements.txt (line 7))\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit->-r requirements.txt (line 7))\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 7)) (6.3.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (4.19.2)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit->-r requirements.txt (line 7))\n",
      "  Downloading narwhals-1.31.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance->-r requirements.txt (line 6)) (2.5)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 7))\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit->-r requirements.txt (line 7))\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting numpy<2.0.0 (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pillow (from vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->vllm==0.6.0->-r requirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.0->vllm==0.6.0->-r requirements.txt (line 1)) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai>=1.0->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.0->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->vllm==0.6.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Collecting lark (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 1)) (1.5.8)\n",
      "Collecting cloudpickle (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting diskcache (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting numba (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading numba-0.61.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 1)) (0.30.2)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 1)) (3.0.1)\n",
      "Collecting pycountry (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pyairports (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading pyairports-2.1.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz->-r requirements.txt (line 3)) (2025.2)\n",
      "Collecting starlette<1.0.0,>=0.30.0 (from prometheus-fastapi-instrumentator>=7.0.0->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.8->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2.8->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.9->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm==0.6.0->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm==0.6.0->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vllm==0.6.0->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vllm==0.6.0->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vllm==0.6.0->-r requirements.txt (line 1)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vllm==0.6.0->-r requirements.txt (line 1)) (2022.12.7)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.6.0->vllm==0.6.0->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.19.1->vllm==0.6.0->-r requirements.txt (line 1)) (0.29.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->vllm==0.6.0->-r requirements.txt (line 1)) (0.5.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm==0.6.0->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm==0.6.0->-r requirements.txt (line 1)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm==0.6.0->-r requirements.txt (line 1)) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm==0.6.0->-r requirements.txt (line 1)) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm==0.6.0->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm==0.6.0->-r requirements.txt (line 1)) (1.18.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/lib/python3/dist-packages (from httplib2->fitz->-r requirements.txt (line 3)) (2.4.7)\n",
      "Collecting importlib-resources>=5.12 (from nibabel->fitz->-r requirements.txt (line 3))\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting prov>=1.5.2 (from nipype->fitz->-r requirements.txt (line 3))\n",
      "  Downloading prov-2.0.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pydot>=1.2.3 (from nipype->fitz->-r requirements.txt (line 3))\n",
      "  Downloading pydot-3.0.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting rdflib>=5.0.0 (from nipype->fitz->-r requirements.txt (line 3))\n",
      "  Downloading rdflib-7.1.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting simplejson>=3.8.0 (from nipype->fitz->-r requirements.txt (line 3))\n",
      "  Downloading simplejson-3.20.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting traits>=6.2 (from nipype->fitz->-r requirements.txt (line 3))\n",
      "  Downloading traits-7.0.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting acres (from nipype->fitz->-r requirements.txt (line 3))\n",
      "  Downloading acres-0.3.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting etelemetry>=0.3.1 (from nipype->fitz->-r requirements.txt (line 3))\n",
      "  Downloading etelemetry-0.3.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting looseversion!=1.2 (from nipype->fitz->-r requirements.txt (line 3))\n",
      "  Downloading looseversion-1.3.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting puremagic (from nipype->fitz->-r requirements.txt (line 3))\n",
      "  Downloading puremagic-1.28-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz->-r requirements.txt (line 3)) (4.9.3)\n",
      "Collecting pathlib>=1.0 (from pyxnat->fitz->-r requirements.txt (line 3))\n",
      "  Downloading pathlib-1.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting h11>=0.8 (from uvicorn[standard]->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading watchfiles-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.0->vllm==0.6.0->-r requirements.txt (line 1)) (1.1.3)\n",
      "Collecting ci-info>=0.2 (from etelemetry>=0.3.1->nipype->fitz->-r requirements.txt (line 3))\n",
      "  Downloading ci_info-0.3.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 7))\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.0->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (2.1.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (2023.7.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (0.12.0)\n",
      "Collecting rdflib>=5.0.0 (from nipype->fitz->-r requirements.txt (line 3))\n",
      "  Downloading rdflib-6.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2->fitz->-r requirements.txt (line 3))\n",
      "  Downloading pyparsing-3.2.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->fitz->-r requirements.txt (line 3)) (1.16.0)\n",
      "Collecting isodate<0.7.0,>=0.6.0 (from rdflib>=5.0.0->nipype->fitz->-r requirements.txt (line 3))\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 1)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 1)) (0.70.16)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba->outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 1))\n",
      "  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->vllm==0.6.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Downloading vllm-0.6.0-cp38-abi3-manylinux1_x86_64.whl (170.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.6/170.6 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gguf-0.9.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lm_format_enforcer-0.10.6-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m188.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading vllm_flash_attn-2.6.1-cp310-cp310-manylinux1_x86_64.whl (75.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl (20.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m160.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m180.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading fitz-0.0.1.dev2-py2.py3-none-any.whl (20 kB)\n",
      "Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m143.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yfinance-0.2.55-py2.py3-none-any.whl (109 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading streamlit-1.43.2-py2.py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m188.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m155.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading frozendict-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mistral_common-1.5.4-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m204.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m182.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.68.2-py3-none-any.whl (606 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.1/606.1 kB\u001b[0m \u001b[31m128.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading outlines-0.0.46-py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m212.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m131.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m191.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m180.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ray-2.44.0-cp310-cp310-manylinux2014_x86_64.whl (67.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m133.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m153.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
      "Downloading configparser-7.2.0-py3-none-any.whl (17 kB)\n",
      "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 kB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nibabel-5.3.2-py3-none-any.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m180.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nipype-1.10.0-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pyxnat-1.6.3-py3-none-any.whl (95 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.4/95.4 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading etelemetry-0.3.1-py3-none-any.whl (6.4 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.9/352.9 kB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading looseversion-1.3.0-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.0/378.0 kB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading narwhals-1.31.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.1/313.1 kB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pathlib-1.0.1-py3-none-any.whl (14 kB)\n",
      "Downloading prov-2.0.1-py3-none-any.whl (421 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydot-3.0.4-py3-none-any.whl (35 kB)\n",
      "Downloading pyparsing-3.2.2-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m132.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading simplejson-3.20.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading traits-7.0.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m139.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m146.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 kB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading acres-0.3.0-py3-none-any.whl (10 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.61.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m199.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading puremagic-1.28-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyairports-2.1.1-py3-none-any.whl (371 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.7/371.7 kB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m140.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ci_info-0.3.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peewee: filename=peewee-3.17.9-py3-none-any.whl size=139079 sha256=12077a18807806d4eb01a592768e7457c42f45dbb183348d24609722caed9463\n",
      "  Stored in directory: /root/.cache/pip/wheels/fd/fd/5e/90b9ec95da4fd6c96237b580ce74f89d6bdea547ad151ab5f4\n",
      "Successfully built peewee\n",
      "Installing collected packages: sentencepiece, pyairports, py-cpuinfo, puremagic, peewee, pathlib, nvidia-ml-py, multitasking, looseversion, websockets, watchdog, uvloop, traits, toml, threadpoolctl, tenacity, smmap, simplejson, python-dotenv, pyparsing, PyMuPDF, pydantic-core, pycountry, protobuf, pillow, partial-json-parser, numpy, narwhals, msgspec, msgpack, llvmlite, lark, joblib, jiter, isodate, interegular, importlib-resources, httptools, h11, frozendict, filelock, diskcache, configparser, configobj, cloudpickle, click, ci-info, cachetools, annotated-types, watchfiles, uvicorn, update_checker, tiktoken, starlette, scipy, rdflib, pyxnat, pydot, pydeck, pydantic, prawcore, numba, nibabel, httpcore, gitdb, gguf, etelemetry, acres, yfinance, scikit-learn, prov, prometheus-fastapi-instrumentator, praw, lm-format-enforcer, jsonschema, httpx, gitpython, fastapi, xformers, vllm-flash-attn, torchvision, ray, openai, nipype, mistral-common, altair, streamlit, fitz, outlines, vllm\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 6.30.1\n",
      "    Uninstalling protobuf-6.30.1:\n",
      "      Successfully uninstalled protobuf-6.30.1\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 9.3.0\n",
      "    Uninstalling Pillow-9.3.0:\n",
      "      Successfully uninstalled Pillow-9.3.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.1\n",
      "    Uninstalling numpy-1.24.1:\n",
      "      Successfully uninstalled numpy-1.24.1\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.9.0\n",
      "    Uninstalling filelock-3.9.0:\n",
      "      Successfully uninstalled filelock-3.9.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.19.2\n",
      "    Uninstalling jsonschema-4.19.2:\n",
      "      Successfully uninstalled jsonschema-4.19.2\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.16.0+cu118\n",
      "    Uninstalling torchvision-0.16.0+cu118:\n",
      "      Successfully uninstalled torchvision-0.16.0+cu118\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyMuPDF-1.25.4 acres-0.3.0 altair-5.5.0 annotated-types-0.7.0 cachetools-5.5.2 ci-info-0.3.0 click-8.1.8 cloudpickle-3.1.1 configobj-5.0.9 configparser-7.2.0 diskcache-5.6.3 etelemetry-0.3.1 fastapi-0.115.12 filelock-3.18.0 fitz-0.0.1.dev2 frozendict-2.4.6 gguf-0.9.1 gitdb-4.0.12 gitpython-3.1.44 h11-0.14.0 httpcore-1.0.7 httptools-0.6.4 httpx-0.28.1 importlib-resources-6.5.2 interegular-0.3.3 isodate-0.6.1 jiter-0.9.0 joblib-1.4.2 jsonschema-4.23.0 lark-1.2.2 llvmlite-0.44.0 lm-format-enforcer-0.10.6 looseversion-1.3.0 mistral-common-1.5.4 msgpack-1.1.0 msgspec-0.19.0 multitasking-0.0.11 narwhals-1.31.0 nibabel-5.3.2 nipype-1.10.0 numba-0.61.0 numpy-1.26.4 nvidia-ml-py-12.570.86 openai-1.68.2 outlines-0.0.46 partial-json-parser-0.2.1.1.post5 pathlib-1.0.1 peewee-3.17.9 pillow-11.1.0 praw-7.8.1 prawcore-2.4.0 prometheus-fastapi-instrumentator-7.1.0 protobuf-5.29.4 prov-2.0.1 puremagic-1.28 py-cpuinfo-9.0.0 pyairports-2.1.1 pycountry-24.6.1 pydantic-2.10.6 pydantic-core-2.27.2 pydeck-0.9.1 pydot-3.0.4 pyparsing-3.2.2 python-dotenv-1.0.1 pyxnat-1.6.3 ray-2.44.0 rdflib-6.3.2 scikit-learn-1.6.1 scipy-1.15.2 sentencepiece-0.2.0 simplejson-3.20.1 smmap-5.0.2 starlette-0.46.1 streamlit-1.43.2 tenacity-9.0.0 threadpoolctl-3.6.0 tiktoken-0.9.0 toml-0.10.2 torchvision-0.19.0 traits-7.0.2 update_checker-0.18.0 uvicorn-0.34.0 uvloop-0.21.0 vllm-0.6.0 vllm-flash-attn-2.6.1 watchdog-6.0.0 watchfiles-1.0.4 websockets-15.0.1 xformers-0.0.27.post2 yfinance-0.2.55\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3db77dd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'frontend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import streamlit as st\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfitz\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/fitz/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfrontend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mop\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'frontend'"
     ]
    }
   ],
   "source": [
    "# import streamlit as st\n",
    "import pandas as pd\n",
    "import fitz\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "import praw\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53cda80b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id='irene93/functioncall_stkissue'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d609627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "# BitsAndBytes 4비트 양자화 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,                             # 4비트 양자화 사용\n",
    "   bnb_4bit_use_double_quant=True,               # 이중 양자화 사용으로 메모리 추가 절약\n",
    "   bnb_4bit_quant_type=\"nf4\",                    # 4비트 양자화 타입 설정(normalized float 4)\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16         # 연산 시 bfloat16 타입 사용\n",
    ")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map={\"\":device},\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c355e46b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53b41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\",\n",
    "       \"function\":   {\n",
    "        \"name\":'get_earnings',\n",
    "        \"description\":'당신은 기업의 실적, 재무재표 또는 현금흐름을 가져오고 분석하는 로봇입니다.',\n",
    "        'parameters':{\n",
    "            \"type\":\"object\",\n",
    "            \"properties\" :{\n",
    "                \"symbol\":{'type':'string', \"description\": '실적 데이터를 찾고자 하는 기업의 symbol'},\n",
    "                'analysis_type':{'type':'string', \"description\":\"\"\"기업의 재무 데이터에서 어떤 정보를 추출하고자 하는지 출력하는 파라미터입니다.\n",
    "                매출 성장률, 순이익 성장률, 영업이익 성장률 과 같은 기업의 성장성을 요청할경우 'growth'라고 출력,\n",
    "                얼마나 효율적으로 이익을 창출하는지 수익성과 관련한 질문일경우 'profitability' 출력,\n",
    "                부채 수준과 재무 건전성과 관련한 질문일경우 'stability' 출력,\n",
    "                현재 가치와 적정 주가와 관련한 질문일경우 'valuation' 출력,\n",
    "                현금을 얼마나 잘 창출하는지 확인하여 재무건전성과 관련한 질문일경우 'cashflow' 출력,\n",
    "                배당 정책과 주식 발행 내역과 관련한 질문일경우 'dividend' 출력,\n",
    "                비용 절감 능력과 효율성과 관련한 질문일경우 'cost' 출력,\n",
    "                그외의 재무,실적,현금흐름과 연관이있지만 파라미터를 찾을수없는경우 'NA'라고 출력합니다.\n",
    "\n",
    "                \"\"\"},\n",
    "                \"type_\":{'type':'string', \"description\": \"연간 데이터 일경우 'yearly' 아닐경우 'quarter' 이라고 표기\"},\n",
    "                \"year\":{'type':'string', \"description\": '데이터를 찾고자 하는 연도, 명시 하지 않을경우 가장 최근 연도 로 설정, 1월일경우 , 해당연도에 데이터가 입력되지않을수있음 따라서 최근연도-1 값을 연도라고 표기 '},\n",
    "                \"quarter\":{'type':'string', \"description\": '데이터를 찾고자 하는 분기로 1~4로 이루어진 숫자, 마지막 또는 최근 분기일경우 또는 언급이 없을경우 -1 이라고 표기 '}\n",
    "            },\n",
    "            \"required\":['symbol', 'analysis_type','type_', 'year','quarter'],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "             \"strict\": True\n",
    "    }},\n",
    "         {\"type\": \"function\",\n",
    "       \"function\":   {\n",
    "        \"name\":'get_consensus',\n",
    "        \"description\":'당신은 기업의 (EPS) 컨센서스 데이터 또는, 매수/매도/홀드 의견 목표주가를 가져와서 분석하는 로봇입니다.',\n",
    "        'parameters':{\n",
    "            \"type\":\"object\",\n",
    "            \"properties\" :{\n",
    "                \"symbol\":{'type':'string', \"description\": ' 데이터를 찾고자 하는 기업의 symbol'},\n",
    "                \"year\":{'type':'string', \"description\": '데이터를 찾고자 하는 연도, 명시 하지 않을경우 가장 최근 연도 로 설정, 1월일경우 , 해당연도에 데이터가 입력되지않을수있음 따라서 최근연도-1 값을 연도라고 표기 '},\n",
    "                \"quarter\":{'type':'string', \"description\": '데이터를 찾고자 하는 분기로 1~4로 이루어진 숫자, 최근 또는 마지막일경우 -1 이라고 표기 '}\n",
    "            },\n",
    "            \"required\":['symbol', 'year','quarter'],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "             \"strict\": True\n",
    "    }},\n",
    "        {\"type\": \"function\",\n",
    "         \"function\":    {\n",
    "        \"name\":'get_issues_summarized',\n",
    "        \"description\":'당신은 특정 기업 또는 키워드의 이슈검색 챗봇입니다.',\n",
    "        'parameters':{\n",
    "            \"type\":\"object\",\n",
    "            \"properties\" :{\n",
    "                \"keyword\":{'type':'string', \"description\": '이슈/현황을 검색하고자 하는 회사명 또는 키워드 in English '},\n",
    "                \"days\":{'type':'integer', \"description\": '검색하고자 하는 기간 예시: 하루, 일주일, 한달, 등등'}\n",
    "\n",
    "            },\n",
    "            \"required\":['keyword','days'],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "             \"strict\": True\n",
    "        }\n",
    "    },\n",
    "    {\"type\": \"function\",\n",
    "       \"function\":   {\n",
    "        \"name\":'get_reddit_hotissue',\n",
    "        \"description\":'당신은 (금융)시장에서 핫한 이슈를 요약하는 챗봇입니다.',\n",
    "        'parameters':{\n",
    "            \"type\":\"object\",\n",
    "            \"properties\" :{\n",
    "                \"days\":{'type':'integer', \"description\": '검색하고자 하는 기간 예시: 하루, 일주일, 한달,일년 등 **질문에 언급이 없을경우 일주일로 지정'}\n",
    "\n",
    "            },\n",
    "            \"required\":['days'],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "             \"strict\": True\n",
    "    }}]\n",
    "\n",
    "\n",
    "def get_issues_summarized(keyword ,days):\n",
    "    redditid = 'mOOCYGbbZZ7_n-x6TucUwQ'\n",
    "    reddit_pw = '2A3xDNKgeB4ld6wOEUfqOPsObU9WLw'\n",
    "\n",
    "    # Reddit API 인증\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=redditid,\n",
    "        client_secret=reddit_pw,\n",
    "        user_agent='test'\n",
    "    )\n",
    "\n",
    "\n",
    "    daysago = datetime.utcnow() - timedelta(days=7)\n",
    "    subreddit = reddit.subreddit('wallstreetbets')\n",
    "\n",
    "    posts_data = []\n",
    "\n",
    "    for post in subreddit.search(keyword, sort='hot', limit=500):  # 최근 500개 게시글 확인\n",
    "        post_date = datetime.utcfromtimestamp(post.created_utc)\n",
    "        if post_date >= daysago:\n",
    "            posts_data.append(\n",
    "                'title :'+ post.title+'\\n'+\n",
    "                'body :' + post.selftext)\n",
    "    titleandbody = '\\n\\n'.join(posts_data)\n",
    "\n",
    "    return titleandbody\n",
    "\n",
    "def get_reddit_hotissue(days):\n",
    "    redditid = 'mOOCYGbbZZ7_n-x6TucUwQ'\n",
    "    reddit_pw = '2A3xDNKgeB4ld6wOEUfqOPsObU9WLw'\n",
    "\n",
    "    # Reddit API 인증\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=redditid,\n",
    "        client_secret=reddit_pw,\n",
    "        user_agent='test'\n",
    "    )\n",
    "\n",
    "\n",
    "    daysago = datetime.utcnow() - timedelta(days=days)\n",
    "    subreddit = reddit.subreddit('wallstreetbets')\n",
    "\n",
    "    posts_data = []\n",
    "    for post in subreddit.hot(limit=500):\n",
    "        post_date = datetime.utcfromtimestamp(post.created_utc)\n",
    "        if post_date >= daysago:\n",
    "            posts_data.append(\n",
    "                'title :'+ post.title+'\\n'+\n",
    "                'body :' + post.selftext)\n",
    "    titleandbody = '\\n\\n'.join(posts_data)\n",
    "\n",
    "    return titleandbody\n",
    "\n",
    "\n",
    "def get_consensus(symbol , year, quarter):\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    # 목표주가\n",
    "    try:\n",
    "        target_price = ticker.analyst_price_targets\n",
    "        # buysell = ticker.recommendations\n",
    "    except:\n",
    "        target_price='cannot get target price'\n",
    "        # buysell = 'cannot get recommendations'\n",
    "    api_key = 'd92779aed523de914055c6b543801a73'\n",
    "    consensus_url = f'https://financialmodelingprep.com/api/v3/earnings-surprises/{symbol}?apikey={api_key}'\n",
    "    consensus_response = requests.get(consensus_url).json()\n",
    "\n",
    "    for consensus in consensus_response:\n",
    "        consensus['year'] =consensus['date'][:4]\n",
    "        consensus['EPS_surprise'] = ((consensus['actualEarningResult'] - consensus['estimatedEarning']) /\n",
    "                                           consensus['estimatedEarning']) * 100\n",
    "\n",
    "\n",
    "    year_consensus = [a for a in consensus_response if a['year']==year or a['year']==str(int(year)-1)   or a['year']==str(int(year)+1 ) ]\n",
    "    if year_consensus:\n",
    "        if quarter =='-1':\n",
    "            result = [year_consensus[0]]\n",
    "        else:\n",
    "            result =  year_consensus\n",
    "    else:\n",
    "\n",
    "        result = consensus_response\n",
    "    if not consensus_response:\n",
    "        return '컨센서스 데이터를 찾을수 없습니다.'\n",
    "\n",
    "    result.append({'target_price':target_price})\n",
    "    return json.dumps(result)\n",
    "    # return result\n",
    "\n",
    "def get_earnings(symbol, analysis_type,type_,year, quarter):\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    # 주가 데이터 가져오기\n",
    "    try:\n",
    "        current_price = ticker.history(period=\"1d\")[\"Close\"].iloc[-1]\n",
    "    except:\n",
    "        current_price= 'currently cannot get current price'\n",
    "\n",
    "    # 재무제표 가져오기\n",
    "    if type_=='yearly':\n",
    "        balance_sheet = ticker.balance_sheet\n",
    "        income_statement = ticker.financials\n",
    "        cash_flow = ticker.cashflow  # 현금흐름표 가져오기\n",
    "    else:\n",
    "        balance_sheet = ticker.quarterly_balance_sheet\n",
    "        income_statement = ticker.quarterly_financials\n",
    "        cash_flow = ticker.quarterly_cashflow  # 현금흐름표 가져오기\n",
    "\n",
    "\n",
    "    earnings = pd.concat([balance_sheet,income_statement])\n",
    "    earnings = pd.concat([earnings, cash_flow])\n",
    "    if earnings.empty :\n",
    "        return \"해당 기업의 재무 정보를 찾을수 없습니다.\"\n",
    "    total_debt = earnings.T['Total Debt'] if 'Total Debt' in earnings.T.columns else 'None'\n",
    "    net_debt =  earnings.T['Net Debt'] if 'Net Debt' in earnings.T.columns else 'None'\n",
    "    total_liabilities = earnings.loc[\"Total Liabilities Net Minority Interest\"].iloc[0]  # 총부채\n",
    "\n",
    "    # growth 분석\n",
    "    try:\n",
    "        total_revenue = earnings.loc[\"Total Revenue\"]\n",
    "        net_income = earnings.loc[\"Net Income\"]\n",
    "        revenue_growth_QoQ = ((total_revenue.iloc[0] - total_revenue.iloc[1]) / total_revenue.iloc[1]) * 100  # 매출 성장률 QoQ\n",
    "        net_income_growth_QoQ = ((net_income.iloc[0] - net_income.iloc[1]) / net_income.iloc[1]) * 100  # 순이익 성장률 QoQ\n",
    "        normalized_ebitda = float(earnings.loc['Normalized EBITDA'].iloc[0])\n",
    "        total_assets = float(earnings.loc['Total Assets'].iloc[0])\n",
    "        invested_capital = float(earnings.loc['Invested Capital'].iloc[0])\n",
    "        # Variables defined separately\n",
    "        if analysis_type == 'growth':\n",
    "            result_dic = {'revenue_growth_QoQ': revenue_growth_QoQ, 'net_income_growth_QoQ': net_income_growth_QoQ,'normalized_ebitda' : normalized_ebitda,'total_assets' : total_assets,'invested_capital':invested_capital}\n",
    "\n",
    "        # 수익성 (profitability)\n",
    "\n",
    "\n",
    "        elif analysis_type=='profitability':\n",
    "            total_revenue = earnings.loc[\"Total Revenue\"]\n",
    "            gross_profit = earnings.loc['Gross Profit']\n",
    "            gross_margin = gross_profit/total_revenue\n",
    "            net_income = earnings.loc[\"Net Income\"]\n",
    "            net_margin = (net_income.iloc[0] / total_revenue.iloc[0]) * 100  # 순이익률\n",
    "            stockholders_equity = earnings.loc[\"Stockholders Equity\"].iloc[0]  # 자기자본\n",
    "            total_assets = earnings.loc['Total Assets']\n",
    "            roe = (net_income.iloc[0] / stockholders_equity) * 100  # ROE\n",
    "            roa = (net_income.iloc[0] / total_assets) * 100  # ROA\n",
    "\n",
    "            EBITDA = earnings.loc['EBITDA']\n",
    "            EBITDA_margin = EBITDA/total_revenue\n",
    "\n",
    "            result_dic = {'total_revenue': total_revenue, 'gross_profit': gross_profit,'gross_margin' : gross_margin,'net_income' : net_income,\n",
    "                          'net_margin':net_margin, 'stockholders_equity':stockholders_equity,'total_assets':total_assets,'roe':roe,'roa':roa,\n",
    "                         'EBITDA':EBITDA, 'EBITDA_margin':EBITDA_margin}\n",
    "\n",
    "\n",
    "\n",
    "        elif analysis_type=='stability':\n",
    "                  ## financial_stability 재무안정성\n",
    "            debt_to_equity_ratio = total_liabilities / stockholders_equity  # 부채비율\n",
    "\n",
    "            current_assets = earnings.loc['Current Assets']\n",
    "            current_liabilities = earnings.loc['Current Liabilities'] # Current Assets / Current Liabilities 유동비율 계산 가능\n",
    "            inventory = earnings.loc['Inventory'] if  'Inventory' in earnings.T.columns else 0  # (Current Assets - Inventory) / Current Liabilities 당좌 비율\n",
    "            # (Current Assets - Inventory) / Current Liabilities 당좌 비율\n",
    "            result_dic = {'debt_to_equity_ratio': debt_to_equity_ratio, 'total_debt': total_debt,'net_debt' : net_debt,\n",
    "                          'current_assets' : current_assets,\n",
    "                          'current_liabilities':current_liabilities, 'inventory':inventory}\n",
    "\n",
    "\n",
    "        # valuation 분석\n",
    "\n",
    "        # 주식 관련 정보 가져오기\n",
    "\n",
    "        elif analysis_type=='valuation':\n",
    "            shares_outstanding = ticker.info[\"sharesOutstanding\"]  # 발행 주식 수\n",
    "            net_income = income_statement.loc[\"Net Income\"]\n",
    "            total_assets = earnings.loc[\"Total Assets\"].iloc[0]  # 총자산\n",
    "            total_liabilities = earnings.loc[\"Total Liabilities Net Minority Interest\"].iloc[0]  # 총부채\n",
    "            book_value = total_assets - total_liabilities  # 순자산\n",
    "            eps = net_income.iloc[0] / shares_outstanding  # 주당순이익 (EPS)\n",
    "            pe_ratio = current_price / eps  # PER\n",
    "            bvps = book_value / shares_outstanding  # 주당순자산가치\n",
    "            pb_ratio = current_price / bvps  # PBR\n",
    "\n",
    "            result_dic = {'shares_outstanding': shares_outstanding,'net_income': net_income.iloc[0],  # 첫 번째 값 사용\n",
    "                'total_assets': total_assets,'total_liabilities': total_liabilities,'book_value': book_value,'eps': eps,\n",
    "                'pe_ratio': pe_ratio,'bvps': bvps,'pb_ratio': pb_ratio}\n",
    "        # cash_flow\n",
    "\n",
    "        elif analysis_type=='cashflow':\n",
    "\n",
    "\n",
    "            cash_and_cash_equivalents = earnings.loc[\"Cash And Cash Equivalents\"].iloc[0]\n",
    "            net_ppe = earnings.loc[\"Net PPE\"].iloc[0]\n",
    "            result_dic = {'cash_and_cash_equivalents': cash_and_cash_equivalents,'net_ppe': net_ppe}\n",
    "\n",
    "        # 주식 배당 (Equity & Dividend)\n",
    "\n",
    "        elif analysis_type=='dividend':\n",
    "            ordinal_shares_number = earnings.T['Ordinary Shares Number']\n",
    "            net_income = income_statement.T['Net Income']\n",
    "            dividends = ticker.dividends\n",
    "            result_dic = {'ordinal_shares_number': ordinal_shares_number,'net_income':net_income, 'dividends': dividends}\n",
    "\n",
    "\n",
    "        ## 비용 구조 분석 비용 절감 능력과 효율성을\n",
    "\n",
    "\n",
    "        elif analysis_type=='cost':\n",
    "            cost_of_revenue = income_statement.loc['Cost Of Revenue']\n",
    "            SG_A = income_statement.loc['Selling General And Administration']\n",
    "            RnD = income_statement.loc['Research And Development']\n",
    "            result_dic = {'cost_of_revenue': cost_of_revenue,'SG_A':SG_A, 'RnD': RnD}\n",
    "\n",
    "        ##etc\n",
    "        # stockholder_equity = earnings.T['Stockholders Equity']\n",
    "        # longterm_debt = earnings.T['Long Term Debt']\n",
    "        # total_cap =  earnings.T['Total Capitalization']\n",
    "\n",
    "\n",
    "        # 예상 성장 값 계산\n",
    "\n",
    "        elif analysis_type=='expectation':\n",
    "            current_eps = ticker.info[\"trailingEps\"]  # 현재 EPS\n",
    "            eps_growth_rate = ticker.info[\"earningsGrowth\"]  # EPS 예상 성장률\n",
    "            current_net_income = ticker.financials.loc[\"Net Income\"].iloc[0]  # 현재 순이익\n",
    "            shares_outstanding = ticker.info[\"sharesOutstanding\"]  # 발행 주식 수\n",
    "            current_revenue = ticker.financials.loc[\"Total Revenue\"].iloc[0]  # 현재 매출\n",
    "            revenue_growth_rate = ticker.info[\"revenueGrowth\"]  # 매출 성장률\n",
    "            result_dic = {'current_eps': current_eps,'eps_growth_rate':eps_growth_rate, 'current_net_income': current_net_income,\n",
    "                         'shares_outstanding':shares_outstanding, 'current_revenue': current_revenue,'revenue_growth_rate':revenue_growth_rate}\n",
    "\n",
    "        else:\n",
    "            print('elseelse')\n",
    "            earningsdf = earnings.T.reset_index()\n",
    "            earningsdf = earningsdf.rename(columns = {'index':'date'})\n",
    "            earningsdf['date'] = earningsdf['date'].dt.strftime('%Y-%m-%d')\n",
    "            result_dic = earningsdf.to_dict('records')\n",
    "            if quarter=='-1':\n",
    "              result_dic= result_dic[0]\n",
    "\n",
    "    except:\n",
    "        print('exceptexcept')\n",
    "        earningsdf = earnings.T.reset_index()\n",
    "        earningsdf = earningsdf.rename(columns = {'index':'date'})\n",
    "        earningsdf['date'] = earningsdf['date'].dt.strftime('%Y-%m-%d')\n",
    "        result_dic = earningsdf.to_dict('records')\n",
    "\n",
    "\n",
    "        if quarter=='-1':\n",
    "            result_dic= result_dic[0]\n",
    "    return str(result_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c35e47d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"당신은 다양한 기능을 호출할 수 있는 AI 모델입니다. 사용자의 요청에 따라 특정 함수를 호출하고, 함수의 시그니처는 <tools></tools> XML 태그 내에 제공됩니다. 함수를 호출할 때는 함수에 필요한 정확한 값을 추정하지 말고 사용자가 제공한 값에 따라 함수를 실행해야 합니다.\n",
    "\n",
    "아래는 사용 가능한 함수들과 각각의 파라미터에 대한 설명입니다:\n",
    "\n",
    "get_issues_summarized\n",
    "\n",
    "설명: 특정 회사 또는 키워드에 대한 이슈를 검색하고 요약합니다.\n",
    "파라미터:\n",
    "keyword: 이슈/현황을 검색하고자 하는 회사명 또는 키워드.\n",
    "days: 검색하고자 하는 기간(일 단위 (integer)).\n",
    "\n",
    "get_reddit_hotissue\n",
    "\n",
    "설명: 금융시장에서 핫한 이슈를 요약합니다.\n",
    "파라미터:\n",
    "days: 검색하고자 하는 기간(일 단위).\n",
    "\n",
    "{name: get_earnings,\n",
    "설명: 기업의 재무재표 또는 현금흐름을 가져오고 분석합니다. 성장률과 같이 이전 년도 데이터가 필요한경우, 이전 년도 데이터도 한번 더 호출하세요\n",
    "파라미터:{symbol: 실적 데이터를 찾고자 하는 기업의 심볼.\n",
    "analysis_type: 분석 유형(growth, profitability, stability, valuation, cashflow, dividend, cost, NA).\n",
    "type_: 데이터 타입(yearly 또는 quarter).\n",
    "year: 데이터를 찾고자 하는 연도 (명시하지 않을경우, 데이터가 존재하는 최근 연도의 데이터를 참조합니다.).\n",
    "quarter: 데이터를 찾고자 하는 분기(명시하지않은 경우 최근 데이터를 조회하도록 -1 을 입력합니다).}}\n",
    "\n",
    "get_consensus\n",
    "\n",
    "설명: 기업의 EPS 컨센서스 데이터 또는 매수/매도/홀드 의견을 가져와서 분석합니다.\n",
    "파라미터:\n",
    "symbol: 데이터를 찾고자 하는 기업의 심볼.\n",
    "year: 데이터를 찾고자 하는 연도.\n",
    "quarter: 데이터를 찾고자 하는 분기.\n",
    "각 함수 호출 시, JSON 객체를 사용하여 함수 이름과 인자들을 <tool_call></tool_call> XML 태그 내에 명시해야 합니다. 함수 호출 예시는 다음과 같습니다:\n",
    "\n",
    "xml\n",
    "Copy\n",
    "<tool_call>\n",
    "{\n",
    "    \"name\": \"get_earnings\",\n",
    "    \"argumedatasetnts\": {\n",
    "        \"symbol\": \"AAPL\",\n",
    "        \"analysis_type\": \"growth\",\n",
    "        \"type_\": \"yearly\" ,\n",
    "        \"year\": \"2024\",\n",
    "        \"quarter\": \"-1\"\n",
    "    }\n",
    "}\n",
    "</tool_call>\n",
    "각 함수의 인자 값을 정확하게 지정해 주세요. 특히, 연도와 분기를 설정할 때 현재 날짜가 1월이나 2월인 경우, 최근 연도의 데이터를 참조하도록 주의해야 합니다.\n",
    "**주의사항\n",
    "함수를 호출할때를 제외하고 한국어로 대답하세요.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a484f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "def get_response(messages):\n",
    "    \n",
    "    encodeds = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "    model_inputs = encodeds.to(device)\n",
    "\n",
    "    input_text = tokenizer.decode(model_inputs[0])\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    eos_token_id = tokenizer.convert_tokens_to_ids(\"<|im_end|>\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=512, eos_token_id=eos_token_id)\n",
    "        return tokenizer.decode(outputs[0][encodeds.shape[-1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "041c6964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_qwen_model(system_prompt, question):\n",
    "    full_messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    messages = full_messages\n",
    "    messages.append({\"role\": \"user\", \"content\": question})\n",
    "    response_message = get_response(messages)\n",
    "    \n",
    "    if '<tool_call>' in response_message:\n",
    "        tool_call_message= {'role':'assistant','content':response_message}\n",
    "        messages.append(tool_call_message)\n",
    "        toolcall_pattern = r'<tool_call>(.*?)</tool_call>'\n",
    "        tool_call_json = re.findall(toolcall_pattern, response_message, re.DOTALL)\n",
    "        for tool_call_str in tool_call_json:\n",
    "\n",
    "            tool_call =  json.loads(tool_call_str)\n",
    "\n",
    "            function_name = tool_call['name']\n",
    "            function_args = tool_call['arguments']\n",
    "\n",
    "            if function_name == \"get_consensus\":\n",
    "                function_response = get_consensus(\n",
    "                  symbol=function_args.get(\"symbol\"),\n",
    "                  year=function_args.get(\"year\"),\n",
    "                  quarter=function_args.get(\"quarter\")\n",
    "                )\n",
    "            elif function_name == \"get_earnings\":\n",
    "                function_response = get_earnings(\n",
    "                  symbol=function_args.get(\"symbol\"),\n",
    "                  analysis_type=function_args.get(\"analysis_type\"),\n",
    "                  type_=function_args.get(\"type_\"),\n",
    "                  year=function_args.get(\"year\"),\n",
    "                  quarter=function_args.get(\"quarter\"),\n",
    "\n",
    "              )\n",
    "            elif function_name == \"get_issues_summarized\":\n",
    "                print('get_issues_summarized called')\n",
    "                function_response = get_issues_summarized(\n",
    "                  keyword=function_args.get(\"keyword\"),\n",
    "                  days=function_args.get(\"days\"),\n",
    "\n",
    "                )\n",
    "            elif function_name == \"get_reddit_hotissue\":\n",
    "                print('get_reddit_hotissue called')\n",
    "                function_response = get_reddit_hotissue(\n",
    "                  days=function_args.get(\"days\"),\n",
    "\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                function_response = json.dumps({\"error\": \"Unknown function\"})\n",
    "                \n",
    "            tool_response = {'role':'user','content':'<tool_reponse>'+function_response+'</tool_reponse>'}\n",
    "            messages.append(tool_response)\n",
    "    final_message = get_response(messages)\n",
    "    return final_message\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b610e0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m messages \u001b[38;5;241m=\u001b[39m full_messages\n\u001b[1;32m      4\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: question})\n\u001b[0;32m----> 5\u001b[0m response_message \u001b[38;5;241m=\u001b[39m \u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m, in \u001b[0;36mget_response\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_response\u001b[39m(messages):\n\u001b[0;32m----> 7\u001b[0m     encodeds \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m encodeds\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(model_inputs[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "question = '구글의 이번분기의 실적 전망치는?'\n",
    "full_messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "messages = full_messages\n",
    "messages.append({\"role\": \"user\", \"content\": question})\n",
    "response_message = get_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d589a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = '<tool_call>{\"name\":\"get_consensus\",\"arguments\": {\"symbol\": \"GOOGL\", \"year\": \"22\", \"quarter\": \"-1\"}}</tool_call>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "06be33e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if '<tool_call>' in response_message:\n",
    "    tool_call_message= {'role':'assistant','content':response_message}\n",
    "    messages.append(tool_call_message)\n",
    "    toolcall_pattern = r'<tool_call>(.*?)</tool_call>'\n",
    "    tool_call_json = re.findall(toolcall_pattern, response_message, re.DOTALL)\n",
    "    for tool_call_str in tool_call_json:\n",
    "\n",
    "        tool_call =  json.loads(tool_call_str)\n",
    "\n",
    "        function_name = tool_call['name']\n",
    "        function_args = tool_call['arguments']\n",
    "\n",
    "        if function_name == \"get_consensus\":\n",
    "            function_response = get_consensus(\n",
    "              symbol=function_args.get(\"symbol\"),\n",
    "              year=function_args.get(\"year\"),\n",
    "              quarter=function_args.get(\"quarter\")\n",
    "            )\n",
    "        elif function_name == \"get_earnings\":\n",
    "            function_response = get_earnings(\n",
    "              symbol=function_args.get(\"symbol\"),\n",
    "              analysis_type=function_args.get(\"analysis_type\"),\n",
    "              type_=function_args.get(\"type_\"),\n",
    "              year=function_args.get(\"year\"),\n",
    "              quarter=function_args.get(\"quarter\"),\n",
    "\n",
    "          )\n",
    "        elif function_name == \"get_issues_summarized\":\n",
    "            print('get_issues_summarized called')\n",
    "            function_response = get_issues_summarized(\n",
    "              keyword=function_args.get(\"keyword\"),\n",
    "              days=function_args.get(\"days\"),\n",
    "\n",
    "            )\n",
    "        elif function_name == \"get_reddit_hotissue\":\n",
    "            print('get_reddit_hotissue called')\n",
    "            function_response = get_reddit_hotissue(\n",
    "              days=function_args.get(\"days\"),\n",
    "\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            function_response = json.dumps({\"error\": \"Unknown function\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8a22158a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.79 GiB is free. Including non-PyTorch memory, this process has 14.09 GiB memory in use. Of the allocated memory 9.07 GiB is allocated by PyTorch, and 4.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tool_response \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<tool_reponse>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mfunction_response\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m</tool_reponse>\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m      2\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend(tool_response)\n\u001b[0;32m----> 3\u001b[0m final_message \u001b[38;5;241m=\u001b[39m \u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[106], line 15\u001b[0m, in \u001b[0;36mget_response\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m     12\u001b[0m eos_token_id \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|im_end|>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 15\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m][encodeds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/transformers/generation/utils.py:2048\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2040\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2041\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2042\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2043\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2044\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2045\u001b[0m     )\n\u001b[1;32m   2047\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2048\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2049\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2059\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2060\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2061\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2062\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2068\u001b[0m     )\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/transformers/generation/utils.py:3008\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3005\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3007\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3008\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   3011\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/transformers/models/qwen2/modeling_qwen2.py:1167\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep)\u001b[0m\n\u001b[1;32m   1164\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1167\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/transformers/models/qwen2/modeling_qwen2.py:976\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    964\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    965\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    966\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    973\u001b[0m         position_embeddings,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 976\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/transformers/models/qwen2/modeling_qwen2.py:702\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    701\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/data/venv310/lib/python3.8/site-packages/transformers/models/qwen2/modeling_qwen2.py:623\u001b[0m, in \u001b[0;36mQwen2SdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;66;03m# The q_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create a causal mask in case q_len == 1.\u001b[39;00m\n\u001b[1;32m    621\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m causal_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m q_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 623\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_dropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    633\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.79 GiB is free. Including non-PyTorch memory, this process has 14.09 GiB memory in use. Of the allocated memory 9.07 GiB is allocated by PyTorch, and 4.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "tool_response = {'role':'user','content':'<tool_reponse>'+function_response+'</tool_reponse>'}\n",
    "messages.append(tool_response)\n",
    "final_message = get_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4f4f0414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc47a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "deceaa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\":system_prompt +'오늘 날짜는 2025-03-09 입니다.'},\n",
    "    {\"role\": \"user\", \"content\": \"아마존의 예상 EPS와 실적 예상치는 어떻게되?\"}\n",
    "]\n",
    "\n",
    "response_message = get_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "713942bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<tool_call>{\"name\":\"get_consensus\",\"argументs\": {\"symbol\": \"AMZN\", \"year\": \"2225\", \"quarter\": \"-1\"}}</tool_call>'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d641b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call_message= {'role':'assistant','content':response_message}\n",
    "messages.append(tool_call_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bee5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7ff37bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e4f38b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"name\":\"get_consensus\",\"argументs\": {\"symbol\": \"AMZN\", \"year\": \"2225\", \"quarter\": \"-1\"}}']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call_str in tool_call_json:\n",
    "    \n",
    "    tool_call =  json.loads(tool_call_str)\n",
    "    \n",
    "    function_name = tool_call['name']\n",
    "    function_args = tool_call['arguments']\n",
    "    \n",
    "    if function_name == \"get_consensus\":\n",
    "        function_response = get_consensus(\n",
    "          symbol=function_args.get(\"symbol\"),\n",
    "          year=function_args.get(\"year\"),\n",
    "          quarter=function_args.get(\"quarter\")\n",
    "        )\n",
    "    elif function_name == \"get_earnings\":\n",
    "        function_response = get_earnings(\n",
    "          symbol=function_args.get(\"symbol\"),\n",
    "          analysis_type=function_args.get(\"analysis_type\"),\n",
    "          type_=function_args.get(\"type_\"),\n",
    "          year=function_args.get(\"year\"),\n",
    "          quarter=function_args.get(\"quarter\"),\n",
    "\n",
    "      )\n",
    "    elif function_name == \"get_issues_summarized\":\n",
    "        print('get_issues_summarized called')\n",
    "        function_response = get_issues_summarized(\n",
    "          keyword=function_args.get(\"keyword\"),\n",
    "          days=function_args.get(\"days\"),\n",
    "\n",
    "        )\n",
    "    elif function_name == \"get_reddit_hotissue\":\n",
    "        print('get_reddit_hotissue called')\n",
    "        function_response = get_reddit_hotissue(\n",
    "          days=function_args.get(\"days\"),\n",
    "\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        function_response = json.dumps({\"error\": \"Unknown function\"})\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9ca9bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_response = {'role':'user','content':'<tool_reponse>'+function_response+'</tool_reponse>'}\n",
    "messages.append(tool_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c9565f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아마존(Amazon)의 예상 EPS와 실적 예상치에 따르면, 예상 EPS는 1.49였으나 실제 EPS는 1.86으로, EPS 서프라이즈는 약 24.83%였습니다. 또한 현재 주가 목표치는 평균적으로 264.71 달러이며 최고치는 306.0 달러, 최저치는 203.0 달러입니다.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dc14f0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '당신은 다양한 기능을 호출할 수 있는 AI 모델입니다. 사용자의 요청에 따라 특정 함수를 호출하고, 함수의 시그니처는 <tools></tools> XML 태그 내에 제공됩니다. 함수를 호출할 때는 함수에 필요한 정확한 값을 추정하지 말고 사용자가 제공한 값에 따라 함수를 실행해야 합니다.\\n\\n아래는 사용 가능한 함수들과 각각의 파라미터에 대한 설명입니다:\\n\\nget_issues_summarized\\n\\n설명: 특정 회사 또는 키워드에 대한 이슈를 검색하고 요약합니다.\\n파라미터:\\nkeyword: 이슈/현황을 검색하고자 하는 회사명 또는 키워드.\\ndays: 검색하고자 하는 기간(일 단위 (integer)).\\n\\nget_reddit_hotissue\\n\\n설명: 금융시장에서 핫한 이슈를 요약합니다.\\n파라미터:\\ndays: 검색하고자 하는 기간(일 단위).\\n\\n{name: get_earnings,\\n설명: 기업의 재무재표 또는 현금흐름을 가져오고 분석합니다. 성장률과 같이 이전 년도 데이터가 필요한경우, 이전 년도 데이터도 한번 더 호출하세요\\n파라미터:{symbol: 실적 데이터를 찾고자 하는 기업의 심볼.\\nanalysis_type: 분석 유형(growth, profitability, stability, valuation, cashflow, dividend, cost, NA).\\ntype_: 데이터 타입(yearly 또는 quarter).\\nyear: 데이터를 찾고자 하는 연도 (명시하지 않을경우, 데이터가 존재하는 최근 연도의 데이터를 참조합니다.).\\nquarter: 데이터를 찾고자 하는 분기(명시하지않은 경우 최근 데이터를 조회하도록 -1 을 입력합니다).}}\\n\\nget_consensus\\n\\n설명: 기업의 EPS 컨센서스 데이터 또는 매수/매도/홀드 의견을 가져와서 분석합니다.\\n파라미터:\\nsymbol: 데이터를 찾고자 하는 기업의 심볼.\\nyear: 데이터를 찾고자 하는 연도.\\nquarter: 데이터를 찾고자 하는 분기.\\n각 함수 호출 시, JSON 객체를 사용하여 함수 이름과 인자들을 <tool_call></tool_call> XML 태그 내에 명시해야 합니다. 함수 호출 예시는 다음과 같습니다:\\n\\nxml\\nCopy\\n<tool_call>\\n{\\n    \"name\": \"get_earnings\",\\n    \"argumedatasetnts\": {\\n        \"symbol\": \"AAPL\",\\n        \"analysis_type\": \"growth\",\\n        \"type_\": \"yearly\" ,\\n        \"year\": \"2024\",\\n        \"quarter\": \"-1\"\\n    }\\n}\\n</tool_call>\\n각 함수의 인자 값을 정확하게 지정해 주세요. 특히, 연도와 분기를 설정할 때 현재 날짜가 1월이나 2월인 경우, 최근 연도의 데이터를 참조하도록 주의해야 합니다.\\n**주의사항\\n함수를 호출할때를 제외하고 한국어로 대답하세요.\\n\\n오늘 날짜는 2025-03-09 입니다.'},\n",
       " {'role': 'user', 'content': '아마존의 예상 EPS와 실적 예상치는 어떻게되?'},\n",
       " [{'role': 'assistant',\n",
       "   'content': '<tool_call>{\"name\":\"get_consensus\",\"argументs\": {\"symbol\": \"AMZN\", \"year\": \"2225\", \"quarter\": \"-1\"}}</tool_call>'}],\n",
       " [{'role': 'user',\n",
       "   'content': '<tool_reponse>[{\"date\": \"2025-02-06\", \"symbol\": \"AMZN\", \"actualEarningResult\": 1.86, \"estimatedEarning\": 1.49, \"year\": \"2025\", \"EPS_surprise\": 24.83221476510068}, {\"target_price\": {\"current\": 193.89, \"high\": 306.0, \"low\": 203.0, \"mean\": 264.70642, \"median\": 270.0}}]</tool_reponse>'}]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "model_inputs = encodeds.to(device)\n",
    "\n",
    "input_text = tokenizer.decode(model_inputs[0])\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "eos_token_id = tokenizer.convert_tokens_to_ids(\"<|im_end|>\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=512, eos_token_id=eos_token_id)\n",
    "    return tokenizer.decode(outputs[0][encodeds.shape[-1]:], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7d63bed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<tool_call>{\"name\":\"get_consensus\",\"argументs\": {\"symbol\": \"AMZN\", \"year\": \"2225\", \"quarter\": \"-1\"}}</tool_call>'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56795c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messeages(system_prompt, question):\n",
    "    todaystr = datetime.strftime(datetime.today(),'%Y-%m-%d')\n",
    "    full_messages = [{\"role\": \"system\", \"content\": system_prompt + todaystr}]\n",
    "\n",
    "    messages = full_messages\n",
    "    messages.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "\n",
    "      # First API call: Ask the model to use the functions\n",
    "    response_message = get_response(messages)\n",
    "    if '<tool_call>' in response_message:\n",
    "        \n",
    "\n",
    "\n",
    "  print(\"Model's response:\")\n",
    "  print(response_message)\n",
    "\n",
    "  # Handle function calls\n",
    "  if response_message.tool_calls:\n",
    "      sftp_toolcall =[]\n",
    "      sftp_tool_response =[]\n",
    "      messages.append(response_message)\n",
    "      for tool_call in response_message.tool_calls:\n",
    "          function_name = tool_call.function.name\n",
    "          function_args = json.loads(tool_call.function.arguments)\n",
    "          print(f\"Function call: {function_name}\")\n",
    "          print(f\"Function arguments: {function_args}\")\n",
    "          argument_str = json.dumps(function_args)\n",
    "          toolcalljson = '{\"name\":\"'+function_name + '\",\"arguments\": '+argument_str+'}'\n",
    "          sftp_toolcall.append('<tool_call>'+toolcalljson+'</tool_call>')\n",
    "\n",
    "\n",
    "          if function_name == \"get_consensus\":\n",
    "              function_response = get_consensus(\n",
    "                  symbol=function_args.get(\"symbol\"),\n",
    "                  year=function_args.get(\"year\"),\n",
    "                  quarter=function_args.get(\"quarter\")\n",
    "              )\n",
    "          elif function_name == \"get_earnings\":\n",
    "              print('get_earning called')\n",
    "              function_response = get_earnings(\n",
    "                  symbol=function_args.get(\"symbol\"),\n",
    "                  analysis_type=function_args.get(\"analysis_type\"),\n",
    "                  type_=function_args.get(\"type_\"),\n",
    "                  year=function_args.get(\"year\"),\n",
    "                  quarter=function_args.get(\"quarter\"),\n",
    "\n",
    "              )\n",
    "              print(function_response)\n",
    "\n",
    "          elif function_name == \"get_issues_summarized\":\n",
    "              print('get_issues_summarized called')\n",
    "              function_response = get_issues_summarized(\n",
    "                  keyword=function_args.get(\"keyword\"),\n",
    "                  days=function_args.get(\"days\"),\n",
    "\n",
    "              )\n",
    "              print(function_response)\n",
    "          elif function_name == \"get_reddit_hotissue\":\n",
    "              print('get_reddit_hotissue called')\n",
    "              function_response = get_reddit_hotissue(\n",
    "                  days=function_args.get(\"days\"),\n",
    "\n",
    "              )\n",
    "              print(function_response)\n",
    "          else:\n",
    "              function_response = json.dumps({\"error\": \"Unknown function\"})\n",
    "\n",
    "          sftp_tool_response.append('<tool_reponse>'+function_response+'</tool_response>')\n",
    "\n",
    "          messages.append({\n",
    "              \"tool_call_id\": tool_call.id,\n",
    "              \"role\": \"tool\",\n",
    "              \"name\": function_name,\n",
    "              \"content\": function_response,\n",
    "          })\n",
    "          # else:\n",
    "          #   continue\n",
    "\n",
    "\n",
    "    # Second API call: Get the final response from the model\n",
    "      final_response = client.chat.completions.create(\n",
    "          model='gpt-4o',\n",
    "          messages=messages,\n",
    "      )\n",
    "      sftp_message = [{\"role\": \"user\", \"content\": question}]\n",
    "      sftp_message.append({'role':'assistant', 'content':''.join(sftp_toolcall)})\n",
    "      sftp_message.append({'role':'user', 'content':''.join(sftp_tool_response)})\n",
    "      sftp_message.append({'role':'assistant','content':final_response.choices[0].message.content})\n",
    "  return sftp_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f210b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "93ade816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<tool_call>{\"name\":\"get_consensus\",\"argументs\": {\"symbol\": \"AMZN\", \"year\": \"2225\", \"quarter\": \"-1\"}}</tool_call>'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7a4aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_reponse = tokenizer.decode(outputs[0][encodeds.shape[-1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd0afc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_reponse = '<tool_call>{\"name\":\"get_consensus\",\"arguments\": {\"symbol\": \"AMZN\", \"year\": \"2224\", \"quarter\": \"-1\"}}</tool_call>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33903fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({'role':'assistant','content':tool_reponse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c14923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_args =  {\"symbol\": \"AMZN\", \"year\": \"2025\", \"quarter\": \"-1\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3dc2ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function_response = get_earnings(\n",
    "#                   symbol=function_args.get(\"symbol\"),\n",
    "#                   analysis_type=function_args.get(\"analysis_type\"),\n",
    "#                   type_=function_args.get(\"type_\"),\n",
    "#                   year=function_args.get(\"year\"),\n",
    "#                   quarter=function_args.get(\"quarter\"),\n",
    "\n",
    "#               )\n",
    "\n",
    "function_response = get_consensus(\n",
    "                  symbol=function_args.get(\"symbol\"),\n",
    "                  year=function_args.get(\"year\"),\n",
    "                  quarter=function_args.get(\"quarter\")\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff4611d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"date\": \"2025-02-06\", \"symbol\": \"AMZN\", \"actualEarningResult\": 1.86, \"estimatedEarning\": 1.49, \"year\": \"2025\", \"EPS_surprise\": 24.83221476510068}, {\"target_price\": {\"current\": 193.89, \"high\": 306.0, \"low\": 203.0, \"mean\": 264.70642, \"median\": 270.0}}]'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "647e33ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tool_response = [{'role':'user','content':'<tool_reponse>'+function_response+'</tool_reponse>'}]\n",
    "messages.append(tool_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6fc1dc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '당신은 다양한 기능을 호출할 수 있는 AI 모델입니다. 사용자의 요청에 따라 특정 함수를 호출하고, 함수의 시그니처는 <tools></tools> XML 태그 내에 제공됩니다. 함수를 호출할 때는 함수에 필요한 정확한 값을 추정하지 말고 사용자가 제공한 값에 따라 함수를 실행해야 합니다.\\n\\n아래는 사용 가능한 함수들과 각각의 파라미터에 대한 설명입니다:\\n\\nget_issues_summarized\\n\\n설명: 특정 회사 또는 키워드에 대한 이슈를 검색하고 요약합니다.\\n파라미터:\\nkeyword: 이슈/현황을 검색하고자 하는 회사명 또는 키워드.\\ndays: 검색하고자 하는 기간(일 단위 (integer)).\\n\\nget_reddit_hotissue\\n\\n설명: 금융시장에서 핫한 이슈를 요약합니다.\\n파라미터:\\ndays: 검색하고자 하는 기간(일 단위).\\n\\n{name: get_earnings,\\n설명: 기업의 재무재표 또는 현금흐름을 가져오고 분석합니다. 성장률과 같이 이전 년도 데이터가 필요한경우, 이전 년도 데이터도 한번 더 호출하세요\\n파라미터:{symbol: 실적 데이터를 찾고자 하는 기업의 심볼.\\nanalysis_type: 분석 유형(growth, profitability, stability, valuation, cashflow, dividend, cost, NA).\\ntype_: 데이터 타입(yearly 또는 quarter).\\nyear: 데이터를 찾고자 하는 연도 (명시하지 않을경우, 데이터가 존재하는 최근 연도의 데이터를 참조합니다.).\\nquarter: 데이터를 찾고자 하는 분기(명시하지않은 경우 최근 데이터를 조회하도록 -1 을 입력합니다).}}\\n\\nget_consensus\\n\\n설명: 기업의 EPS 컨센서스 데이터 또는 매수/매도/홀드 의견을 가져와서 분석합니다.\\n파라미터:\\nsymbol: 데이터를 찾고자 하는 기업의 심볼.\\nyear: 데이터를 찾고자 하는 연도.\\nquarter: 데이터를 찾고자 하는 분기.\\n각 함수 호출 시, JSON 객체를 사용하여 함수 이름과 인자들을 <tool_call></tool_call> XML 태그 내에 명시해야 합니다. 함수 호출 예시는 다음과 같습니다:\\n\\nxml\\nCopy\\n<tool_call>\\n{\\n    \"name\": \"get_earnings\",\\n    \"argumedatasetnts\": {\\n        \"symbol\": \"AAPL\",\\n        \"analysis_type\": \"growth\",\\n        \"type_\": \"yearly\" ,\\n        \"year\": \"2024\",\\n        \"quarter\": \"-1\"\\n    }\\n}\\n</tool_call>\\n각 함수의 인자 값을 정확하게 지정해 주세요. 특히, 연도와 분기를 설정할 때 현재 날짜가 1월이나 2월인 경우, 최근 연도의 데이터를 참조하도록 주의해야 합니다.\\n**주의사항\\n함수를 호출할때를 제외하고 한국어로 대답하세요.\\n\\n오늘 날짜는 2025-03-09 입니다.'},\n",
       " {'role': 'user', 'content': '아마존의 예상 EPS와 실적 예상치는 어떻게되?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '<tool_call>{\"name\":\"get_consensus\",\"arguments\": {\"symbol\": \"AMZN\", \"year\": \"2224\", \"quarter\": \"-1\"}}</tool_call>'},\n",
       " [{'role': 'user',\n",
       "   'content': '<tool_reponse>[{\"date\": \"2025-02-06\", \"symbol\": \"AMZN\", \"actualEarningResult\": 1.86, \"estimatedEarning\": 1.49, \"year\": \"2025\", \"EPS_surprise\": 24.83221476510068}, {\"target_price\": {\"current\": 193.89, \"high\": 306.0, \"low\": 203.0, \"mean\": 264.70642, \"median\": 270.0}}]</tool_reponse>'}]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "52a716d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_response_encoded = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a709881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아마존(AMZN)의 예상 EPS와 실적 예상치를 확인할 수 있습니다. 곧 데이터를 분석하여 결과를 제공하겠습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encodeds = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "model_inputs = encodeds.to(device)\n",
    "\n",
    "input_text = tokenizer.decode(model_inputs[0])\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "eos_token_id = tokenizer.convert_tokens_to_ids(\"<|im_end|>\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=512, eos_token_id=eos_token_id)\n",
    "    print(tokenizer.decode(outputs[0][encodeds.shape[-1]:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "534f705c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7791a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '당신은 다양한 기능을 호출할 수 있는 AI 모델입니다. 사용자의 요청에 따라 특정 함수를 호출하고, 함수의 시그니처는 <tools></tools> XML 태그 내에 제공됩니다. 함수를 호출할 때는 함수에 필요한 정확한 값을 추정하지 말고 사용자가 제공한 값에 따라 함수를 실행해야 합니다.\\n\\n아래는 사용 가능한 함수들과 각각의 파라미터에 대한 설명입니다:\\n\\nget_issues_summarized\\n\\n설명: 특정 회사 또는 키워드에 대한 이슈를 검색하고 요약합니다.\\n파라미터:\\nkeyword: 이슈/현황을 검색하고자 하는 회사명 또는 키워드.\\ndays: 검색하고자 하는 기간(일 단위 (integer)).\\n\\nget_reddit_hotissue\\n\\n설명: 금융시장에서 핫한 이슈를 요약합니다.\\n파라미터:\\ndays: 검색하고자 하는 기간(일 단위).\\n\\n{name: get_earnings,\\n설명: 기업의 재무재표 또는 현금흐름을 가져오고 분석합니다. 성장률과 같이 이전 년도 데이터가 필요한경우, 이전 년도 데이터도 한번 더 호출하세요\\n파라미터:{symbol: 실적 데이터를 찾고자 하는 기업의 심볼.\\nanalysis_type: 분석 유형(growth, profitability, stability, valuation, cashflow, dividend, cost, NA).\\ntype_: 데이터 타입(yearly 또는 quarter).\\nyear: 데이터를 찾고자 하는 연도 (명시하지 않을경우, 데이터가 존재하는 최근 연도의 데이터를 참조합니다.).\\nquarter: 데이터를 찾고자 하는 분기(명시하지않은 경우 최근 데이터를 조회하도록 -1 을 입력합니다).}}\\n\\nget_consensus\\n\\n설명: 기업의 EPS 컨센서스 데이터 또는 매수/매도/홀드 의견을 가져와서 분석합니다.\\n파라미터:\\nsymbol: 데이터를 찾고자 하는 기업의 심볼.\\nyear: 데이터를 찾고자 하는 연도.\\nquarter: 데이터를 찾고자 하는 분기.\\n각 함수 호출 시, JSON 객체를 사용하여 함수 이름과 인자들을 <tool_call></tool_call> XML 태그 내에 명시해야 합니다. 함수 호출 예시는 다음과 같습니다:\\n\\nxml\\nCopy\\n<tool_call>\\n{\\n    \"name\": \"get_earnings\",\\n    \"argumedatasetnts\": {\\n        \"symbol\": \"AAPL\",\\n        \"analysis_type\": \"growth\",\\n        \"type_\": \"yearly\" ,\\n        \"year\": \"2024\",\\n        \"quarter\": \"-1\"\\n    }\\n}\\n</tool_call>\\n각 함수의 인자 값을 정확하게 지정해 주세요. 특히, 연도와 분기를 설정할 때 현재 날짜가 1월이나 2월인 경우, 최근 연도의 데이터를 참조하도록 주의해야 합니다.\\n**주의사항\\n함수를 호출할때를 제외하고 한국어로 대답하세요.\\n\\n오늘 날짜는 2025-03-09 입니다.'},\n",
       " {'role': 'user', 'content': '테슬라의 최근 성장률은 어때?'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = encodeds.to(device)\n",
    "\n",
    "input_text = tokenizer.decode(model_inputs[0])\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "eos_token_id = tokenizer.convert_tokens_to_ids(\"<|im_end|>\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=512, eos_token_id=eos_token_id)\n",
    "    print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ac4ec85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([151644,   8948,    198,  64795,  82528,  33704, 135392,  54116,  66019,\n",
       "         17877,  95499,  47836,  28733,  64521,  15235,  54070, 142713,  78952,\n",
       "            13,  40720, 131958, 142163,  19391, 126629, 142976,  58440,  18411,\n",
       "         95499, 126204,     11,  58440,  20401,  44518,  48606,  83036, 125746,\n",
       "         16560,    366,  15918,   1472,  15918,     29,  11874,  74361,    250,\n",
       "         48606,  66136,  19391, 130094, 130885,     13,  58440,  18411,  95499,\n",
       "         47836,  53618,  16560,  58440,  19391, 134028,  36055, 133085,  23573,\n",
       "         93668,  57835,  29281,  87425, 126254,  34395,  40720, 130427, 130094,\n",
       "         23573,  45563,  19391, 126629,  58440,  18411,  85788, 129264, 130650,\n",
       "           382,  52959,  53442,  16560,  40720, 143964,  58440, 134771, 126804,\n",
       "        126317,  20401,  54969,  50340,  56039,  33861,  19391, 128605, 133828,\n",
       "         78952,   1447,    455,  90232,  10160,   5612,   1506,    271, 125624,\n",
       "         79632,     25, 142976,  98005,  55054, 129549,  10764,  92120, 130109,\n",
       "         29346,  19391, 128605,  23084, 144018,  18411,  85322,  77226, 126204,\n",
       "         85997, 125535,  60838,    624, 126793,  50340,  56039,  33861,    510,\n",
       "         19863,     25,  23084, 144018,     14, 126407, 130803,  17877,  85322,\n",
       "         77226, 126204,  25715, 128956,  98005,  55054,  79632, 129549,  10764,\n",
       "         92120, 130109,  29346,    624,  13778,     25,  85322,  77226, 126204,\n",
       "         25715, 128956,  54116,  62275,      7,  32077, 129400,  80901,    320,\n",
       "         11662,    593,    382,    455,   1288,  20090,  33433,  11159,    271,\n",
       "        125624,  79632,     25,  40771,    230, 128024, 133627,  56475,  20136,\n",
       "           104,  23573,  23084, 144018,  18411,  85997, 125535,  60838,    624,\n",
       "        126793,  50340,  56039,  33861,    510,  13778,     25,  85322,  77226,\n",
       "        126204,  25715, 128956,  54116,  62275,      7,  32077, 129400,  80901,\n",
       "          3593,  47006,     25,    633,     62,  10118,    819,    345, 125624,\n",
       "         79632,     25,  54116, 124517,  20401, 129242, 125054,  57132, 126414,\n",
       "        129549, 141526, 125052, 144015,  63154,  17877,  88846,  57268,  34395,\n",
       "        128618, 129150,  60838,     13, 128677,  40853, 127834,  53680, 131050,\n",
       "         23084,  65865, 127041,    226,  47985,  54248,  19969, 134028,  65306,\n",
       "         40281,     11,  23084,  65865, 127041,    226,  47985,  54248,  47985,\n",
       "        138903, 126366,  95499,  91145,    198, 126793,  50340,  56039,  33861,\n",
       "         12547,  18785,     25, 126423,  80968,  54248,  18411, 138037,  34395,\n",
       "         25715, 128956,  54116, 124517,  20401,  28927,    105, 130454,    624,\n",
       "         34484,   1819,     25, 128618, 129150, 126310, 128909,   3268,  19089,\n",
       "            11,  62236,     11,  19753,     11,  50162,     11,   8350,   4965,\n",
       "            11,  45880,     11,   2783,     11,  20662,   4292,   1313,  23211,\n",
       "         54248,  74361,    222,  43866,  28281,    398, 129549,   8338,   4292,\n",
       "          3157,     25,  54248,  18411, 138037,  34395,  25715, 128956,  77353,\n",
       "         47985,    320,  79632,  29326,  87425, 136982,  65306,  40281,     11,\n",
       "         54248,  19969, 134015,  42905, 139465,  77353,  47985,  20401,  54248,\n",
       "         18411, 127969,  92817,  60838,     13,   4292,  32015,     25,  54248,\n",
       "         18411, 138037,  34395,  25715, 128956, 128618,  20487,      7,  79632,\n",
       "         29326,  87425, 144372,  33704,  49052, 139465,  54248,  18411,  97167,\n",
       "        137531,    481,     16,  16751,    226,  42349,  60838,    568,  47449,\n",
       "           455,  31971,  13626,    271, 125624,  79632,     25,  54116, 124517,\n",
       "         20401,  40607,  89095,    101, 127601,  26698,  24897,  54248, 129549,\n",
       "        126932,  23259,     14, 129865,  47985,     14, 144117,  29346, 140264,\n",
       "         17877,  88846,  80573,  26698, 128618, 129150,  60838,    624, 126793,\n",
       "         50340,  56039,  33861,    510,  18785,     25,  54248,  18411, 138037,\n",
       "         34395,  25715, 128956,  54116, 124517,  20401,  28927,    105, 130454,\n",
       "           624,   3157,     25,  54248,  18411, 138037,  34395,  25715, 128956,\n",
       "         77353,  47985,    624,  32015,     25,  54248,  18411, 138037,  34395,\n",
       "         25715, 128956, 128618,  20487,    624, 126317,  58440,  95499,  44518,\n",
       "            11,   4718,  75232,  18411,  40720,  82190,  58440,  86034,  53680,\n",
       "         58677,  25715, 129125,    220, 151657, 151658,  11874,  74361,    250,\n",
       "         48606,  66136,  19391, 130345,  29326, 129264, 130650,     13,  58440,\n",
       "         95499,  95617,  29326,  16560, 139107, 138691,   1447,   6455,    198,\n",
       "         12106,    198, 151657,    198,    515,    262,    330,    606,    788,\n",
       "           330,    455,     62,  10118,    819,    756,    262,    330,    858,\n",
       "         38155,   8369,  65677,    788,    341,    286,    330,  18785,    788,\n",
       "           330,  82916,     43,    756,    286,    330,  34484,   1819,    788,\n",
       "           330,  73089,    756,    286,    330,   1313,     62,    788,    330,\n",
       "          3157,    398,      1,  13493,    286,    330,   3157,    788,    330,\n",
       "            17,     15,     17,     19,    756,    286,    330,  32015,    788,\n",
       "          6523,     16,    698,    262,    456,    532, 151658,    198, 126317,\n",
       "         58440,  20401,  58677,  25715,  93668,  36055, 133085, 128555,  66790,\n",
       "         29281,  33883,  55673,  50302,     13, 136115,     11,  77353,  47985,\n",
       "         80573, 128618, 131777,  65880,  47836,  53618, 132270,  37195,    254,\n",
       "        137771,  19969,    220,     16, 128514, 129835,    220,     17, 128514,\n",
       "         31328,  49052,     11, 139465,  77353,  47985,  20401,  54248,  18411,\n",
       "        127969,  92817, 137531,  55673,  20401, 129264, 130650,    624,    334,\n",
       "        130788, 131193,    198,  77953,  23259,  18411,  95499,  47836, 131866,\n",
       "         18411,  62071, 128792, 126204, 130092,  31079,  17380,  60960, 132760,\n",
       "         91145,    382,  57268, 127478,  37195,    254, 137771,  16560,    220,\n",
       "            17,     15,     17,     20,     12,     15,     18,     12,     15,\n",
       "            24,  38150,  21953,     13, 151645,    198, 151644,    872,    198,\n",
       "        130229, 139039,  50340,  20401, 139465, 128677,  40853, 127834,  33704,\n",
       "        124685, 131866,     30, 151645,    198, 151644,  77091,    198, 151657,\n",
       "          4913,    606,   3252,    455,     62,  10118,    819,   2198,    858,\n",
       "         69924,     82,     82,    788,   5212,  18785,    788,    330,     51,\n",
       "          7984,     32,    497,    330,  34484,   1819,    788,    330,  73089,\n",
       "           497,    330,   1313,     62,    788,    330,   3157,    398,    497,\n",
       "           330,   3157,    788,    330,     17,     17,     17,     19,    497,\n",
       "           330,  32015,    788,   6523,     16,  30975, 151658, 151645],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bd4bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42ec87c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
       "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
       "             13, 151645,    198, 151644,    872,    198,     27,  14172,   1288,\n",
       "           1025,   7309,      6,    265,   7140,  49182,  13337,     78,     48,\n",
       "           1210,    220,     15,     13,     24,     19,     22,     20,     22,\n",
       "             23,     18,     20,     18,     19,     21,     21,     18,     20,\n",
       "             24,     19,     11,    364,   4711,  67377,  49182,  13337,     78,\n",
       "             48,   1210,    481,     20,     17,     13,     19,     21,     18,\n",
       "             19,     24,     22,     20,     21,     21,     20,     15,     19,\n",
       "             19,     19,     11,    364,  38460,   2204,   4489,   3235,   1210,\n",
       "            220,     16,     20,     18,     24,     17,     15,     15,     15,\n",
       "             15,     15,     15,     13,     15,     11,    364,   5035,  53299,\n",
       "           1210,    220,     16,     17,     17,     15,     22,     15,     15,\n",
       "             15,     15,     15,     15,     15,     13,     15,     11,    364,\n",
       "          42014,    291,  16388,   2174,   1210,    220,     23,     15,     22,\n",
       "             24,     16,     15,     15,     15,     15,     15,     15,     13,\n",
       "             15,   5361,  14172,   1288,   1025,     29, 151645,    198, 151644,\n",
       "          77091,    198]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_response_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a55b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
