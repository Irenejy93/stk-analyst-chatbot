{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07984c3e-df7c-4d64-b0d3-c1c5ce07a650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd  /workspace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6aabc4-f461-439d-b695-98e249f81e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "with open(f'./data/final.pkl' , 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5239f2bd-90e1-499f-acfa-adacae5329de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.10/dist-packages (2.2.0)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0) (12.8.93)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.24.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (6.30.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers==4.45.1 in /usr/local/lib/python3.10/dist-packages (4.45.1)\n",
      "Requirement already satisfied: datasets==3.0.1 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
      "Requirement already satisfied: accelerate==0.34.2 in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
      "Requirement already satisfied: evaluate==0.4.3 in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
      "Requirement already satisfied: bitsandbytes==0.44.0 in /usr/local/lib/python3.10/dist-packages (0.44.0)\n",
      "Requirement already satisfied: trl==0.11.1 in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
      "Requirement already satisfied: peft==0.13.0 in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
      "Requirement already satisfied: qwen-vl-utils in /usr/local/lib/python3.10/dist-packages (0.0.10)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==3.0.1) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (3.11.13)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (5.9.6)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (2.2.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl==0.11.1) (0.9.17)\n",
      "Requirement already satisfied: av in /usr/local/lib/python3.10/dist-packages (from qwen-vl-utils) (14.2.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from qwen-vl-utils) (9.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (2022.12.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.34.2) (12.8.93)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11.1) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11.1) (13.9.4)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11.1) (1.7.1)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11.1) (4.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.0.1) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.1) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.34.2) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.34.2) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.11.1) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install Pytorch & other libraries\n",
    "%pip install \"torch==2.2.0\" tensorboard pillow\n",
    " \n",
    "# Install Hugging Face libraries\n",
    "%pip install  --upgrade \\\n",
    "  \"transformers==4.45.1\" \\\n",
    "  \"datasets==3.0.1\" \\\n",
    "  \"accelerate==0.34.2\" \\\n",
    "  \"evaluate==0.4.3\" \\\n",
    "  \"bitsandbytes==0.44.0\" \\\n",
    "  \"trl==0.11.1\" \\\n",
    "  \"peft==0.13.0\" \\\n",
    "  \"qwen-vl-utils\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a385b3d9-feee-4a77-97cf-e1be9ea0a9b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (1.11.1.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (23.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: flash-attn in /usr/local/lib/python3.10/dist-packages (2.7.4.post1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.2.0)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.8.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# GPU가 Flash Attention을 지원하는지 확인\n",
    "assert torch.cuda.get_device_capability()[0] >= 8, 'Hardware not supported for Flash Attention'\n",
    "\n",
    "# Flash Attention 설치\n",
    "!pip install ninja packaging\n",
    "!pip install flash-attn --no-build-isolation --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d57dcc-2f92-4cca-965a-c92f9208c4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"당신은 다양한 기능을 호출할 수 있는 AI 모델입니다. 사용자의 요청에 따라 특정 함수를 호출하고, 함수의 시그니처는 <tools></tools> XML 태그 내에 제공됩니다. 함수를 호출할 때는 함수에 필요한 정확한 값을 추정하지 말고 사용자가 제공한 값에 따라 함수를 실행해야 합니다.\n",
    "\n",
    "아래는 사용 가능한 함수들과 각각의 파라미터에 대한 설명입니다:\n",
    "\n",
    "get_issues_summarized\n",
    "\n",
    "설명: 특정 회사 또는 키워드에 대한 이슈를 검색하고 요약합니다.\n",
    "파라미터:\n",
    "keyword: 이슈/현황을 검색하고자 하는 회사명 또는 키워드.\n",
    "days: 검색하고자 하는 기간(일 단위 (integer)).\n",
    "\n",
    "get_reddit_hotissue\n",
    "\n",
    "설명: 금융시장에서 핫한 이슈를 요약합니다.\n",
    "파라미터:\n",
    "days: 검색하고자 하는 기간(일 단위).\n",
    "\n",
    "{name: get_earnings,\n",
    "설명: 기업의 재무재표 또는 현금흐름을 가져오고 분석합니다. 성장률과 같이 이전 년도 데이터가 필요한경우, 이전 년도 데이터도 한번 더 호출하세요\n",
    "파라미터:{symbol: 실적 데이터를 찾고자 하는 기업의 심볼.\n",
    "analysis_type: 분석 유형(growth, profitability, stability, valuation, cashflow, dividend, cost, NA).\n",
    "type_: 데이터 타입(yearly 또는 quarter).\n",
    "year: 데이터를 찾고자 하는 연도 (명시하지 않을경우, 데이터가 존재하는 최근 연도의 데이터를 참조합니다.).\n",
    "quarter: 데이터를 찾고자 하는 분기(명시하지않은 경우 최근 데이터를 조회하도록 -1 을 입력합니다).}}\n",
    "\n",
    "get_consensus\n",
    "\n",
    "설명: 기업의 EPS 컨센서스 데이터 또는 매수/매도/홀드 의견을 가져와서 분석합니다.\n",
    "파라미터:\n",
    "symbol: 데이터를 찾고자 하는 기업의 심볼.\n",
    "year: 데이터를 찾고자 하는 연도.\n",
    "quarter: 데이터를 찾고자 하는 분기.\n",
    "각 함수 호출 시, JSON 객체를 사용하여 함수 이름과 인자들을 <tool_call></tool_call> XML 태그 내에 명시해야 합니다. 함수 호출 예시는 다음과 같습니다:\n",
    "\n",
    "xml\n",
    "Copy\n",
    "<tool_call>\n",
    "{\n",
    "    \"name\": \"get_earnings\",\n",
    "    \"arguments\": {\n",
    "        \"symbol\": \"AAPL\",\n",
    "        \"analysis_type\": \"growth\",\n",
    "        \"type_\": \"yearly\" ,\n",
    "        \"year\": \"2024\",\n",
    "        \"quarter\": \"-1\"\n",
    "    }\n",
    "}\n",
    "</tool_call>\n",
    "각 함수의 인자 값을 정확하게 지정해 주세요. 특히, 연도와 분기를 설정할 때 현재 날짜가 1월이나 2월인 경우, 최근 연도의 데이터를 참조하도록 주의해야 합니다.\n",
    "**주의사항\n",
    "함수를 호출할때를 제외하고 한국어로 대답하세요.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a423c46-9261-40cb-801d-53bca5c3fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messeges = [{'message':d} for d in data]\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_list(messeges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e224a3b-9f73-44a5-8755-dc97c089bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list 형태의 dataset을 Dataset 객체로 변환\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def format_data(example):\n",
    "\n",
    "    # Iterate through each item in the batch (examples are structured as lists of values)\n",
    "    if len(example)<3:\n",
    "    \n",
    "        return {'messages':[{\n",
    "                \"content\": system_prompt,\n",
    "                \"role\": \"system\"\n",
    "            },\n",
    "                example[0],\n",
    "                example[1]]\n",
    "               }\n",
    "    else:\n",
    "        return {'messages':[{\n",
    "                \"content\": system_prompt,\n",
    "                \"role\": \"system\"\n",
    "            },\n",
    "                example[0],\n",
    "                example[1],\n",
    "                {'content':example[2]['content'][:4000]+'</tool_response>','role':'user'},\n",
    "                example[3]]\n",
    "               }\n",
    "            \n",
    "    \n",
    "# Apply the formatting on dataset\n",
    "dataset = [format_data(sample) for sample in data]\n",
    "\n",
    "dataset = Dataset.from_list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64215a02-a644-4dec-b77a-d773dcc6f79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 863\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "480cfe44-918e-4df4-8022-055efe24e78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3a307632fc48fabddd6bea413cb1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# 허깅페이스 모델 ID\n",
    "model_id = \"Qwen/Qwen2.5-7B-Instruct\" \n",
    "\n",
    "# BitsAndBytes 4비트 양자화 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,                             # 4비트 양자화 사용\n",
    "   bnb_4bit_use_double_quant=True,               # 이중 양자화 사용으로 메모리 추가 절약\n",
    "   bnb_4bit_quant_type=\"nf4\",                    # 4비트 양자화 타입 설정(normalized float 4)\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16         # 연산 시 bfloat16 타입 사용\n",
    ")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2680af-7446-4e99-a258-d952ac34458d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "당신은 다양한 기능을 호출할 수 있는 AI 모델입니다. 사용자의 요청에 따라 특정 함수를 호출하고, 함수의 시그니처는 <tools></tools> XML 태그 내에 제공됩니다. 함수를 호출할 때는 함수에 필요한 정확한 값을 추정하지 말고 사용자가 제공한 값에 따라 함수를 실행해야 합니다.\n",
      "\n",
      "아래는 사용 가능한 함수들과 각각의 파라미터에 대한 설명입니다:\n",
      "\n",
      "get_issues_summarized\n",
      "\n",
      "설명: 특정 회사 또는 키워드에 대한 이슈를 검색하고 요약합니다.\n",
      "파라미터:\n",
      "keyword: 이슈/현황을 검색하고자 하는 회사명 또는 키워드.\n",
      "days: 검색하고자 하는 기간(일 단위 (integer)).\n",
      "\n",
      "get_reddit_hotissue\n",
      "\n",
      "설명: 금융시장에서 핫한 이슈를 요약합니다.\n",
      "파라미터:\n",
      "days: 검색하고자 하는 기간(일 단위).\n",
      "\n",
      "{name: get_earnings,\n",
      "설명: 기업의 재무재표 또는 현금흐름을 가져오고 분석합니다. 성장률과 같이 이전 년도 데이터가 필요한경우, 이전 년도 데이터도 한번 더 호출하세요\n",
      "파라미터:{symbol: 실적 데이터를 찾고자 하는 기업의 심볼.\n",
      "analysis_type: 분석 유형(growth, profitability, stability, valuation, cashflow, dividend, cost, NA).\n",
      "type_: 데이터 타입(yearly 또는 quarter).\n",
      "year: 데이터를 찾고자 하는 연도 (명시하지 않을경우, 데이터가 존재하는 최근 연도의 데이터를 참조합니다.).\n",
      "quarter: 데이터를 찾고자 하는 분기(명시하지않은 경우 최근 데이터를 조회하도록 -1 을 입력합니다).}}\n",
      "\n",
      "get_consensus\n",
      "\n",
      "설명: 기업의 EPS 컨센서스 데이터 또는 매수/매도/홀드 의견을 가져와서 분석합니다.\n",
      "파라미터:\n",
      "symbol: 데이터를 찾고자 하는 기업의 심볼.\n",
      "year: 데이터를 찾고자 하는 연도.\n",
      "quarter: 데이터를 찾고자 하는 분기.\n",
      "각 함수 호출 시, JSON 객체를 사용하여 함수 이름과 인자들을 <tool_call></tool_call> XML 태그 내에 명시해야 합니다. 함수 호출 예시는 다음과 같습니다:\n",
      "\n",
      "xml\n",
      "Copy\n",
      "<tool_call>\n",
      "{\n",
      "    \"name\": \"get_earnings\",\n",
      "    \"arguments\": {\n",
      "        \"symbol\": \"AAPL\",\n",
      "        \"analysis_type\": \"growth\",\n",
      "        \"type_\": \"yearly\" ,\n",
      "        \"year\": \"2024\",\n",
      "        \"quarter\": \"-1\"\n",
      "    }\n",
      "}\n",
      "</tool_call>\n",
      "각 함수의 인자 값을 정확하게 지정해 주세요. 특히, 연도와 분기를 설정할 때 현재 날짜가 1월이나 2월인 경우, 최근 연도의 데이터를 참조하도록 주의해야 합니다.\n",
      "**주의사항\n",
      "함수를 호출할때를 제외하고 한국어로 대답하세요.\n",
      "\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "최근 일주일 동안 금융 시장에서 어떤 이슈들이 핫했나요?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>{\"name\":\"get_reddit_hotissue\",\"arguments\": {\"days\": 7}}</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "<tool_reponse>title :What Are Your Moves Tomorrow, March 10, 2025\n",
      "body :This post contains content not supported on old Reddit. [Click here to view the full post](https://sh.reddit.com/r/wallstreetbets/comments/1j7g4c1)\n",
      "\n",
      "title :Weekly Earnings Thread 3/10 - 3/14\n",
      "body :\n",
      "\n",
      "title :🤷\n",
      "body :\n",
      "\n",
      "title :For those wondering why we really need  yields to drop.\n",
      "body :\n",
      "\n",
      "title :+39k trade, 40k->100k in 2 months, as a senior in college\n",
      "body :\n",
      "\n",
      "title :Lost 8k YTD thanks to the trade war. Sold all my SOXL\n",
      "body :Silver lining is that I made 38K last year on SOXL and TQQQ because I sold some shares at the peek in June 2024, roughly half portfolio at the time.  My made  little money on CC’s but not nearly enough to make up for the hemorrhaging. \n",
      "\n",
      "title :Saving the market with my puts.\n",
      "body :Biggest yolo of my life. And I never make money on options. \n",
      "\n",
      "title :US Fund Flows: US Investors Pump Billions into Active ETFs Amid Shaky Market Start in 2025\n",
      "body :\n",
      "\n",
      "title :US car payment delinquencies reach 33-year high: Analysis\n",
      "body :\n",
      "\n",
      "title :GRRR - Gorilla technology group - A 'deep' dive into\n",
      "body :https://preview.redd.it/9y63pv35ione1.png?width=870&format=png&auto=webp&s=12f4f27b42603aa177a784a495d24d16d0eeae77\n",
      "\n",
      "Hey everyone, I'm sharing this DD because, compared to other analyses I've seen, there are some key differences and divergences. This is based on my own research, and I wanted to provide a more complete perspective on Gorilla Technology (GRRR) based on what I found . I’m just a regular small investor (not a financial advisor), currently holding 1,200 shares along with call options ahead of their webinar. I’ve spent a significant amount of time digging into their background, SEC filings, and the controversy surrounding short-seller allegations. If I’ve missed anything or if someone has a different take, I’d be happy to discuss it.\n",
      "\n",
      "# Is this an AI-generated post?\n",
      "\n",
      "https://preview.redd.it/qenkz99k0pne1.png?width=2433&format=png&auto=webp&s=663e356896e5e3b91f1177f67f541a5bac3d6cda\n",
      "\n",
      "https://preview.redd.it/zpxw7ysu0pne1.png?width=2496&format=png&auto=webp&s=738d68ee81e93eb571caae590636c4f33603698a\n",
      "\n",
      "Many of you in the comments are suggesting that this was AI-generated. While I can say that I spent a lot of time writing and revising it (especially since English isn’t my first language), you’ll never have proof of that. What I *can* show you, however, are some of the methods I use to conduct my analyses. And yes, I used my LLM to format the text— < typical indent used, because who wants to read a long, poorly structured post? I mean, even I wouldn’t want to read my own post again like that.\n",
      "\n",
      "# What Does Gorilla Technology Do?\n",
      "\n",
      "Gorilla operates at the intersection of AI, Industrial IoT, and cybersecurity, providing AI-driven solutions for smart cities and security analytics. Their platforms power video surveillance, facial recognition, network security, and IoT deployments. They work across Asia, the Middle East, Europe, and Latin America.\n",
      "\n",
      "Recent MoUs (memorandums of understanding) indicate massive growth potential, including a $1.8B Thai electric-grid modernization project and a large smart government contract in Egypt. While MoUs aren’t finalized deals, they show strong business momentum.\n",
      "\n",
      "On March 3, **The Bear Cave**—a research firm that digs up short ideas—released a note raising what they called “cautionary flags” about Gorilla Technology. They highlighted Gorilla’s roughly **1,200%** stock price jump over six months, pointing to the hype around a series of deals and MoUs (Memorandums of Understanding) that might not be fully locked in. The Bear Cave basically argued that investor excitement might be getting ahead of real fundamentals, noting things like Gorilla’s Cayman Islands registration, workforce distribution (a lot in Taiwan), and its pivot into AI under CEO and Chairman **Jay Chandan**.\n",
      "\n",
      "Naturally, short-selling activity popped up around the same time. But high short interest doesn’t automatically mean the short thesis is correct; it just</tool_response><|im_end|>\n",
      "<|im_start|>assistant\n",
      "최근 일주일 동안 금융 시장에서는 여러 주목할 만한 이슈와 사건들이 있었습니다.\n",
      "\n",
      "1. **상위무역 기조**: 미국 투자자들은 2025년 초 시장이 불안정한 상황에서 적극적으로 액티브 상장지수펀드(ETF)에 자금을 투입하고 있는 것으로 나타났습니다.\n",
      "\n",
      "2. **미국 자동차 대출 연체율**: 미국 내 자동차 대출 연체율이 33년 만에 최고치를 기록했다는 분석이 나오며 주목받고 있습니다.\n",
      "\n",
      "3. **고릴라 테크놀로지(GRRR)**: 고릴라 테크놀로지가 최근 MOU 체결과 관련된 논란 속에서 주목받고 있습니다. 특히 태국의 전기 그리드 현대화 프로젝트와 이집트의 스마트 정부 계약과 관련된 메모랜덤 언급이 있었습니다.\n",
      "\n",
      "4. **미국 내 기업 수익 보고**: 다양한 기업의 최근 수익 보고가 있었으며, 투자자들은 시장의 변동성을 주의 깊게 살피고 있습니다.\n",
      "\n",
      "5. **레딧 주식 이슈**: $RDDT로 불리는 레딧 주식이 최근 시장에서 상당한 가격 하락을 겪고 있는데, 이는 주로 지정학적 문제와 관련이 있는 것으로 보입니다.\n",
      "\n",
      "이런 이슈들은 시장의 변동성과 투자 판단에 영향을 미칠 수 있는 주요 요소들로, 투자자들은 이러한 정보들을 고려하여 투자 전략을 수립해야 할 것입니다.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 적용\n",
    "text = tokenizer.apply_chat_template(\n",
    "    dataset[0][\"messages\"], tokenize=False, add_generation_prompt=False\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a7a88eb-c0af-42a5-a857-bb0cc4cf78a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    " \n",
    "# QLoRA 논문 및 Sebastian Raschka 실험에 기반한 LoRA Conifg\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0,\n",
    "        r=16,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "\n",
    "# from transformers import TrainingArguments\n",
    "from trl import SFTConfig\n",
    "\n",
    "args = SFTConfig(\n",
    "    output_dir=\"qwen2.5-7b-functioncall\",     # 저장될 디렉토리와 저장소 ID\n",
    "    num_train_epochs=10,                      # 학습할 총 에포크 수\n",
    "    per_device_train_batch_size=8,           # 장치당 학습 배치 크기\n",
    "    gradient_accumulation_steps=2,           # 역전파/가중치 업데이트 전 누적할 스텝 수\n",
    "    gradient_checkpointing=True,             # 메모리 절약을 위한 그래디언트 체크포인팅 사용\n",
    "    optim=\"adamw_torch_fused\",               # 퓨즈드 AdamW 옵티마이저 사용\n",
    "    logging_steps=10,                        # 10스텝마다 로그 기록\n",
    "    save_strategy=\"steps\",                   # 특정 스텝마다 체크포인트 저장\n",
    "    save_steps=50,\n",
    "    bf16=True,                              # bfloat16 정밀도 사용\n",
    "    tf32=True,                              # tf32 정밀도 사용\n",
    "    learning_rate=1e-4,                     # 학습률 (QLoRA 논문 기반)\n",
    "    max_grad_norm=0.3,                      # 최대 그래디언트 노름 (QLoRA 논문 기반)\n",
    "    warmup_ratio=0.03,                      # 워밍업 비율 (QLoRA 논문 기반)\n",
    "    lr_scheduler_type=\"constant\",           # 고정 학습률 스케줄러 사용\n",
    "    push_to_hub=False,                      # 허브에 모델 업로드 안 함\n",
    "    report_to=\"tensorboard\",                # 텐서보드에 메트릭 기록\n",
    "    remove_unused_columns=False,\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a4b993f-2e3c-4412-b04d-6cf6f838a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    new_batch = {\n",
    "        \"input_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "    \n",
    "    for example in batch:\n",
    "        # messages의 각 내용에서 개행문자 제거\n",
    "        clean_messages = []\n",
    "        for message in example[\"messages\"]:\n",
    "            clean_message = {\n",
    "                \"role\": message[\"role\"],\n",
    "                \"content\": message[\"content\"]\n",
    "            }\n",
    "            clean_messages.append(clean_message)\n",
    "        \n",
    "        # 깨끗해진 메시지로 템플릿 적용\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            clean_messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        ).strip()\n",
    "        \n",
    "        # 텍스트를 토큰화\n",
    "        tokenized = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=max_seq_length,\n",
    "            padding=False,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        \n",
    "        input_ids = tokenized[\"input_ids\"]\n",
    "        attention_mask = tokenized[\"attention_mask\"]\n",
    "        \n",
    "        # 레이블 초기화\n",
    "        labels = [-100] * len(input_ids)\n",
    "        \n",
    "        # assistant 응답 부분 찾기\n",
    "        im_start = \"<|im_start|>\"\n",
    "        im_end = \"<|im_end|>\"\n",
    "        assistant = \"assistant\"\n",
    "        \n",
    "        # 토큰 ID 가져오기\n",
    "        im_start_tokens = tokenizer.encode(im_start, add_special_tokens=False)\n",
    "        im_end_tokens = tokenizer.encode(im_end, add_special_tokens=False)\n",
    "        assistant_tokens = tokenizer.encode(assistant, add_special_tokens=False)\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(input_ids):\n",
    "            # <|im_start|>assistant 찾기\n",
    "            if (i + len(im_start_tokens) <= len(input_ids) and \n",
    "                input_ids[i:i+len(im_start_tokens)] == im_start_tokens):\n",
    "                \n",
    "                # assistant 토큰 찾기\n",
    "                assistant_pos = i + len(im_start_tokens)\n",
    "                if (assistant_pos + len(assistant_tokens) <= len(input_ids) and \n",
    "                    input_ids[assistant_pos:assistant_pos+len(assistant_tokens)] == assistant_tokens):\n",
    "                    \n",
    "                    # assistant 응답의 시작 위치로 이동\n",
    "                    current_pos = assistant_pos + len(assistant_tokens)\n",
    "                    \n",
    "                    # <|im_end|>를 찾을 때까지 레이블 설정\n",
    "                    while current_pos < len(input_ids):\n",
    "                        if (current_pos + len(im_end_tokens) <= len(input_ids) and \n",
    "                            input_ids[current_pos:current_pos+len(im_end_tokens)] == im_end_tokens):\n",
    "                            # <|im_end|> 토큰도 레이블에 포함\n",
    "                            for j in range(len(im_end_tokens)):\n",
    "                                labels[current_pos + j] = input_ids[current_pos + j]\n",
    "                            break\n",
    "                        labels[current_pos] = input_ids[current_pos]\n",
    "                        current_pos += 1\n",
    "                    \n",
    "                    i = current_pos\n",
    "                \n",
    "            i += 1\n",
    "        \n",
    "        new_batch[\"input_ids\"].append(input_ids)\n",
    "        new_batch[\"attention_mask\"].append(attention_mask)\n",
    "        new_batch[\"labels\"].append(labels)\n",
    "    \n",
    "    # 패딩 적용\n",
    "    max_length = max(len(ids) for ids in new_batch[\"input_ids\"])\n",
    "    \n",
    "    for i in range(len(new_batch[\"input_ids\"])):\n",
    "        padding_length = max_length - len(new_batch[\"input_ids\"][i])\n",
    "        \n",
    "        new_batch[\"input_ids\"][i].extend([tokenizer.pad_token_id] * padding_length)\n",
    "        new_batch[\"attention_mask\"][i].extend([0] * padding_length)\n",
    "        new_batch[\"labels\"][i].extend([-100] * padding_length)\n",
    "    \n",
    "    # 텐서로 변환\n",
    "    for k, v in new_batch.items():\n",
    "        new_batch[k] = torch.tensor(v)\n",
    "    \n",
    "    return new_batch\n",
    "\n",
    "def print_tokens_and_labels(batch):\n",
    "    input_ids = batch[\"input_ids\"][0].tolist()\n",
    "    labels = batch[\"labels\"][0].tolist()\n",
    "    \n",
    "    print(\"\\n토큰과 레이블 비교:\")\n",
    "    print(f\"{'Token ID':<10} {'Token':<30} {'Label':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for token_id, label in zip(input_ids, labels):\n",
    "        token = tokenizer.decode([token_id])\n",
    "        label_str = str(label) if label != -100 else \"-100\"\n",
    "        print(f\"{token_id:<10} {token:<30} {label_str:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc830518-ccff-4b01-9436-d77d6bc07725",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70e8172e-d095-46dc-ac8b-a46b98e61393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "처리된 배치 데이터:\n",
      "입력 ID 형태: torch.Size([1, 2200])\n",
      "어텐션 마스크 형태: torch.Size([1, 2200])\n",
      "레이블 형태: torch.Size([1, 2200])\n"
     ]
    }
   ],
   "source": [
    "# collate_fn 테스트 (배치 크기 1로)\n",
    "max_seq_length = 8192  \n",
    "batch = collate_fn([example])\n",
    "print(\"\\n처리된 배치 데이터:\")\n",
    "print(\"입력 ID 형태:\", batch[\"input_ids\"].shape)\n",
    "print(\"어텐션 마스크 형태:\", batch[\"attention_mask\"].shape)\n",
    "print(\"레이블 형태:\", batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8890e5a5-c8c5-492f-98fe-bac9787733a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력에 대한 정수 인코딩 결과:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 198, 151657, 4913, 606, 3252, 455, 1288, 20090, 33433, 11159, 2198, 16370, 788, 5212, 13778, 788, 220, 22, 3417, 151658, 151645, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 198, 128215, 125722, 83556, 54330, 32077, 126322, 126246, 40771, 230, 128024, 44518, 40853, 129889, 127296, 55673, 87608, 47836, 62107, 23573, 23084, 144018, 80573, 138629, 126253, 35339, 127750, 382, 16, 13, 3070, 55902, 80901, 125054, 126346, 54116, 92817, 95518, 132662, 10764, 230, 105, 25715, 25715, 128901, 220, 17, 15, 17, 20, 126216, 83315, 44518, 40853, 12802, 126488, 126246, 29281, 23573, 58034, 130803, 56475, 135968, 131529, 128552, 23872, 94, 131131, 131196, 58034, 40853, 21329, 23259, 144419, 29346, 7, 42239, 8, 19391, 64577, 125052, 17877, 10764, 230, 105, 43866, 126204, 64521, 132091, 135513, 138097, 38231, 382, 17, 13, 3070, 56039, 124785, 64577, 57089, 125625, 60960, 69923, 77353, 49543, 132841, 95518, 132662, 66136, 64577, 57089, 125625, 60960, 69923, 77353, 49543, 132841, 12802, 220, 18, 18, 126216, 62107, 19391, 81173, 34395, 59698, 18411, 54116, 49664, 128836, 16560, 128618, 129150, 12802, 137298, 124905, 55673, 87608, 132872, 34395, 128472, 382, 18, 13, 3070, 34395, 135379, 50340, 10764, 72509, 81133, 137666, 17380, 21329, 6699, 8106, 49, 32295, 25, 126429, 135379, 50340, 10764, 72509, 81133, 137666, 17380, 21329, 19969, 139465, 11418, 52, 48364, 112, 88781, 53680, 129985, 52300, 127041, 120, 129804, 77596, 235, 56475, 55673, 87608, 132872, 34395, 128472, 13, 136115, 74361, 250, 124785, 20401, 56419, 20487, 126342, 29346, 141526, 66845, 56290, 84255, 17380, 144644, 28626, 80573, 23084, 126886, 28626, 20401, 141767, 125544, 28626, 36055, 63089, 94203, 125535, 53680, 129985, 52300, 51391, 129439, 136499, 144452, 139957, 128911, 12802, 35339, 127750, 382, 19, 13, 3070, 56039, 124785, 66136, 54116, 124517, 28733, 131870, 63332, 34395, 95518, 135392, 54116, 124517, 20401, 139465, 28733, 131870, 63332, 34395, 19969, 132236, 127378, 11, 10764, 230, 105, 25715, 25715, 128901, 44518, 40853, 20401, 46319, 57089, 132818, 55673, 20401, 130507, 232, 57801, 127166, 129262, 34395, 128472, 382, 20, 13, 3070, 126673, 144934, 55673, 76337, 23084, 144018, 95518, 400, 97068, 51, 17380, 126488, 132920, 5140, 254, 230, 144934, 55673, 76337, 12802, 139465, 44518, 40853, 56475, 58034, 64795, 23573, 35509, 126614, 53900, 132772, 17877, 23894, 103, 34395, 134563, 11, 23084, 16560, 55673, 17380, 66790, 29281, 124632, 80968, 126674, 80573, 129985, 12802, 64521, 132091, 63332, 78952, 382, 12802, 125120, 23084, 144018, 128901, 44518, 40853, 20401, 46319, 57089, 32831, 53680, 10764, 230, 105, 25715, 140569, 19391, 126440, 129321, 17877, 125714, 142588, 28733, 64521, 55673, 35711, 85997, 43590, 64850, 17380, 11, 10764, 230, 105, 25715, 25715, 128901, 131367, 60039, 129125, 126429, 125476, 82190, 10764, 230, 105, 25715, 56419, 138279, 17877, 28733, 126702, 129264, 95002, 130882, 13, 151645]\n"
     ]
    }
   ],
   "source": [
    "print('입력에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"labels\"][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caa8673c-ff0b-4e6c-a495-d6ef174da621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "max_seq_length = 8192  # 모델과 데이터셋 패킹을 위한 최대 시퀀스 길이\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    max_seq_length=max_seq_length,  # 최대 시퀀스 길이 설정\n",
    "    train_dataset=dataset,\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "725a44cd-f178-49dc-bca2-6dfbfa197f42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 학습 시작\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mtrain(resume_from_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqwen2.5-7b-functioncall/checkpoint-500\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \u001b[38;5;66;03m# 모델이 자동으로 허브와 output_dir에 저장됨\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 모델 저장\u001b[39;00m\n\u001b[1;32m      5\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model()   \u001b[38;5;66;03m# 최종 모델을 저장\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "trainer.train(resume_from_checkpoint=\"qwen2.5-7b-functioncall/checkpoint-500\")   # 모델이 자동으로 허브와 output_dir에 저장됨\n",
    "\n",
    "# 모델 저장\n",
    "trainer.save_model()   # 최종 모델을 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3f2c08b-6737-49bb-84c2-2eb925dad7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-09 11:20:19--  https://raw.githubusercontent.com/ukairia777/LLM-Finetuning-tutorial/main/merge.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\n",
      "Length: 1351 (1.3K) [text/plain]\n",
      "Saving to: ‘merge.py’\n",
      "\n",
      "merge.py            100%[===================>]   1.32K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-03-09 11:20:19 (69.6 MB/s) - ‘merge.py’ saved [1351/1351]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/ukairia777/LLM-Finetuning-tutorial/main/merge.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c28c5a8a-b143-4258-8a5a-64d24b427881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d68dd06-77e7-448f-8ef9-982c06a95000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.2\n",
      "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (12.1.105)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2) (12.1.105)\n",
      "Collecting triton==2.2.0 (from torch==2.2)\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2) (1.3.0)\n",
      "Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nccl-cu12, nvidia-cudnn-cu12, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.0.0\n",
      "    Uninstalling triton-3.0.0:\n",
      "      Successfully uninstalled triton-3.0.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0\n",
      "    Uninstalling torch-2.4.0:\n",
      "      Successfully uninstalled torch-2.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cudnn-cu12-8.9.2.26 nvidia-nccl-cu12-2.19.3 torch-2.2.0 triton-2.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "142ca8d2-d627-4f05-b52e-829a8e1b761f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model: Qwen/Qwen2.5-7B-Instruct\n",
      "model.safetensors.index.json: 100%|████████| 27.8k/27.8k [00:00<00:00, 56.5MB/s]\n",
      "Downloading shards:   0%|                                 | 0/4 [00:00<?, ?it/s]\n",
      "model-00001-of-00004.safetensors:   0%|             | 0.00/3.95G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|     | 31.5M/3.95G [00:00<00:17, 226MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|     | 62.9M/3.95G [00:00<00:15, 244MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|     | 94.4M/3.95G [00:00<00:15, 247MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▏     | 126M/3.95G [00:00<00:15, 244MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▏     | 157M/3.95G [00:00<00:16, 234MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▎     | 189M/3.95G [00:00<00:16, 232MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▎     | 220M/3.95G [00:00<00:15, 236MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▍     | 252M/3.95G [00:01<00:15, 233MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▍     | 283M/3.95G [00:01<00:16, 227MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▍     | 315M/3.95G [00:01<00:15, 230MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|▌     | 346M/3.95G [00:01<00:15, 235MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▌     | 377M/3.95G [00:01<00:14, 244MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▌     | 409M/3.95G [00:01<00:14, 240MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▋     | 440M/3.95G [00:01<00:14, 240MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|▋     | 472M/3.95G [00:01<00:14, 238MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|▊     | 503M/3.95G [00:02<00:14, 237MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|▊     | 535M/3.95G [00:02<00:14, 240MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|▊     | 566M/3.95G [00:02<00:14, 240MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|▉     | 598M/3.95G [00:02<00:13, 243MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|▉     | 629M/3.95G [00:02<00:13, 243MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█     | 661M/3.95G [00:02<00:13, 247MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|█     | 692M/3.95G [00:02<00:13, 247MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|█     | 724M/3.95G [00:03<00:13, 245MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|█▏    | 755M/3.95G [00:03<00:13, 245MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|█▏    | 786M/3.95G [00:03<00:13, 242MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|█▏    | 818M/3.95G [00:03<00:12, 242MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|█▎    | 849M/3.95G [00:03<00:14, 219MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|█▎    | 881M/3.95G [00:03<00:13, 221MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|█▍    | 912M/3.95G [00:03<00:14, 207MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|█▍    | 944M/3.95G [00:04<00:13, 215MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|█▍    | 975M/3.95G [00:04<00:13, 220MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|█▎   | 1.01G/3.95G [00:04<00:15, 196MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|█▎   | 1.03G/3.95G [00:04<00:15, 194MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  27%|█▎   | 1.06G/3.95G [00:04<00:13, 208MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|█▍   | 1.09G/3.95G [00:04<00:13, 216MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|█▍   | 1.12G/3.95G [00:04<00:12, 223MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  29%|█▍   | 1.15G/3.95G [00:05<00:12, 224MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|█▌   | 1.18G/3.95G [00:05<00:12, 227MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|█▌   | 1.22G/3.95G [00:05<00:12, 225MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|█▌   | 1.25G/3.95G [00:05<00:11, 233MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|█▌   | 1.28G/3.95G [00:05<00:13, 197MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  33%|█▋   | 1.31G/3.95G [00:05<00:12, 211MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|█▋   | 1.34G/3.95G [00:05<00:11, 221MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|█▋   | 1.37G/3.95G [00:06<00:11, 227MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|█▊   | 1.41G/3.95G [00:06<00:10, 232MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|█▊   | 1.44G/3.95G [00:06<00:10, 237MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|█▊   | 1.47G/3.95G [00:06<00:13, 178MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|█▉   | 1.50G/3.95G [00:06<00:12, 194MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|█▉   | 1.53G/3.95G [00:06<00:11, 205MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|█▉   | 1.56G/3.95G [00:06<00:10, 217MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|██   | 1.59G/3.95G [00:07<00:10, 228MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  41%|██   | 1.63G/3.95G [00:07<00:10, 229MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|██   | 1.66G/3.95G [00:07<00:09, 232MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|██▏  | 1.69G/3.95G [00:07<00:12, 180MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|██▏  | 1.72G/3.95G [00:07<00:11, 196MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|██▏  | 1.75G/3.95G [00:07<00:10, 209MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|██▎  | 1.78G/3.95G [00:07<00:10, 216MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  46%|██▎  | 1.81G/3.95G [00:08<00:09, 221MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|██▎  | 1.85G/3.95G [00:08<00:09, 227MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|██▍  | 1.88G/3.95G [00:08<00:08, 230MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|██▍  | 1.91G/3.95G [00:08<00:11, 180MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  49%|██▍  | 1.94G/3.95G [00:08<00:10, 195MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|██▍  | 1.97G/3.95G [00:08<00:10, 191MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|██▌  | 2.00G/3.95G [00:09<00:09, 202MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|██▌  | 2.03G/3.95G [00:09<00:09, 211MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|██▌  | 2.07G/3.95G [00:09<00:08, 221MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  53%|██▋  | 2.10G/3.95G [00:09<00:09, 193MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|██▋  | 2.13G/3.95G [00:09<00:08, 205MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|██▋  | 2.16G/3.95G [00:09<00:08, 219MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|██▊  | 2.19G/3.95G [00:09<00:07, 224MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|██▊  | 2.22G/3.95G [00:10<00:07, 227MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  57%|██▊  | 2.25G/3.95G [00:10<00:07, 230MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|██▉  | 2.29G/3.95G [00:10<00:07, 233MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|██▉  | 2.32G/3.95G [00:10<00:08, 182MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|██▉  | 2.35G/3.95G [00:10<00:08, 194MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|███  | 2.38G/3.95G [00:10<00:07, 208MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|███  | 2.41G/3.95G [00:11<00:07, 210MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|███  | 2.44G/3.95G [00:11<00:06, 220MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|███▏ | 2.47G/3.95G [00:11<00:06, 227MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|███▏ | 2.51G/3.95G [00:11<00:06, 230MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|███▏ | 2.54G/3.95G [00:11<00:07, 186MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|███▎ | 2.57G/3.95G [00:11<00:06, 200MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|███▎ | 2.60G/3.95G [00:11<00:06, 211MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  67%|███▎ | 2.63G/3.95G [00:12<00:06, 216MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  68%|███▍ | 2.66G/3.95G [00:12<00:05, 221MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  68%|███▍ | 2.69G/3.95G [00:12<00:05, 228MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  69%|███▍ | 2.73G/3.95G [00:12<00:06, 182MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|███▍ | 2.76G/3.95G [00:12<00:06, 197MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|███▌ | 2.79G/3.95G [00:12<00:05, 207MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|███▌ | 2.82G/3.95G [00:12<00:05, 212MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███▌ | 2.85G/3.95G [00:13<00:04, 220MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|███▋ | 2.88G/3.95G [00:13<00:04, 222MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  74%|███▋ | 2.92G/3.95G [00:13<00:04, 226MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███▋ | 2.95G/3.95G [00:13<00:05, 186MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███▊ | 2.98G/3.95G [00:13<00:04, 198MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███▊ | 3.01G/3.95G [00:13<00:04, 187MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███▊ | 3.04G/3.95G [00:14<00:04, 203MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|███▉ | 3.07G/3.95G [00:14<00:04, 212MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███▉ | 3.10G/3.95G [00:14<00:03, 218MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███▉ | 3.14G/3.95G [00:14<00:03, 205MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|████ | 3.17G/3.95G [00:14<00:04, 190MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  81%|████ | 3.20G/3.95G [00:14<00:03, 204MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████ | 3.23G/3.95G [00:14<00:03, 211MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████▏| 3.26G/3.95G [00:15<00:03, 219MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████▏| 3.29G/3.95G [00:15<00:02, 226MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████▏| 3.32G/3.95G [00:15<00:02, 228MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  85%|████▎| 3.36G/3.95G [00:15<00:02, 197MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|████▎| 3.39G/3.95G [00:15<00:02, 209MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  87%|████▎| 3.42G/3.95G [00:15<00:02, 217MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  87%|████▎| 3.45G/3.95G [00:15<00:02, 226MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  88%|████▍| 3.48G/3.95G [00:16<00:02, 231MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  89%|████▍| 3.51G/3.95G [00:16<00:01, 237MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  90%|████▍| 3.54G/3.95G [00:16<00:01, 238MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  91%|████▌| 3.58G/3.95G [00:16<00:02, 182MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  91%|████▌| 3.61G/3.95G [00:16<00:01, 200MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  92%|████▌| 3.64G/3.95G [00:16<00:01, 212MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|████▋| 3.67G/3.95G [00:16<00:01, 221MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  94%|████▋| 3.70G/3.95G [00:17<00:01, 221MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  95%|████▋| 3.73G/3.95G [00:17<00:00, 224MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  95%|████▊| 3.76G/3.95G [00:17<00:00, 233MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  96%|████▊| 3.80G/3.95G [00:17<00:00, 178MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  97%|████▊| 3.83G/3.95G [00:17<00:00, 195MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  98%|████▉| 3.86G/3.95G [00:17<00:00, 208MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  99%|████▉| 3.89G/3.95G [00:18<00:00, 219MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  99%|████▉| 3.92G/3.95G [00:18<00:00, 224MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors: 100%|█████| 3.95G/3.95G [00:18<00:00, 216MB/s]\u001b[A\n",
      "Downloading shards:  25%|██████▎                  | 1/4 [00:18<00:55, 18.44s/it]\n",
      "model-00002-of-00004.safetensors:   0%|             | 0.00/3.86G [00:00<?, ?B/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   1%|     | 21.0M/3.86G [00:00<00:21, 176MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   1%|     | 41.9M/3.86G [00:00<00:19, 194MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   2%|     | 73.4M/3.86G [00:00<00:17, 215MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   3%|▏     | 105M/3.86G [00:00<00:16, 223MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   4%|▏     | 136M/3.86G [00:00<00:16, 226MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   4%|▎     | 168M/3.86G [00:00<00:16, 225MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   5%|▎     | 199M/3.86G [00:00<00:15, 231MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   6%|▎     | 231M/3.86G [00:01<00:15, 232MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   7%|▍     | 262M/3.86G [00:01<00:15, 235MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   8%|▍     | 294M/3.86G [00:01<00:15, 235MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   8%|▌     | 325M/3.86G [00:01<00:14, 240MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   9%|▌     | 357M/3.86G [00:01<00:14, 244MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  10%|▌     | 388M/3.86G [00:01<00:14, 246MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  11%|▋     | 419M/3.86G [00:01<00:14, 246MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|▋     | 451M/3.86G [00:01<00:14, 244MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|▋     | 482M/3.86G [00:02<00:14, 236MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  13%|▊     | 514M/3.86G [00:02<00:14, 234MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  14%|▊     | 545M/3.86G [00:02<00:13, 238MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  15%|▉     | 577M/3.86G [00:02<00:14, 225MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  16%|▉     | 608M/3.86G [00:02<00:14, 228MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  17%|▉     | 640M/3.86G [00:02<00:13, 234MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  17%|█     | 671M/3.86G [00:03<00:18, 168MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  18%|█     | 703M/3.86G [00:03<00:16, 188MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  19%|█▏    | 734M/3.86G [00:03<00:15, 203MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  20%|█▏    | 765M/3.86G [00:03<00:14, 214MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  21%|█▏    | 797M/3.86G [00:03<00:13, 219MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  21%|█▎    | 828M/3.86G [00:03<00:13, 225MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  22%|█▎    | 860M/3.86G [00:03<00:13, 230MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  23%|█▍    | 891M/3.86G [00:03<00:12, 240MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  24%|█▍    | 923M/3.86G [00:04<00:12, 240MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  25%|█▍    | 954M/3.86G [00:04<00:13, 223MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  26%|█▌    | 986M/3.86G [00:04<00:12, 236MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  26%|█▎   | 1.02G/3.86G [00:04<00:11, 240MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  27%|█▎   | 1.05G/3.86G [00:04<00:11, 240MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  28%|█▍   | 1.08G/3.86G [00:04<00:11, 241MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  29%|█▍   | 1.11G/3.86G [00:04<00:11, 233MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  30%|█▍   | 1.14G/3.86G [00:05<00:11, 235MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  30%|█▌   | 1.17G/3.86G [00:05<00:11, 237MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  31%|█▌   | 1.21G/3.86G [00:05<00:11, 233MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  32%|█▌   | 1.24G/3.86G [00:05<00:11, 236MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  33%|█▋   | 1.27G/3.86G [00:05<00:10, 245MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  34%|█▋   | 1.30G/3.86G [00:05<00:10, 243MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  34%|█▋   | 1.33G/3.86G [00:05<00:10, 242MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  35%|█▊   | 1.36G/3.86G [00:05<00:10, 242MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  36%|█▊   | 1.39G/3.86G [00:06<00:10, 244MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  37%|█▊   | 1.43G/3.86G [00:06<00:09, 245MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  38%|█▉   | 1.46G/3.86G [00:06<00:09, 242MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  39%|█▉   | 1.49G/3.86G [00:06<00:10, 235MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  39%|█▉   | 1.52G/3.86G [00:06<00:09, 237MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  40%|██   | 1.55G/3.86G [00:06<00:09, 239MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  41%|██   | 1.58G/3.86G [00:06<00:09, 239MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  42%|██   | 1.61G/3.86G [00:06<00:09, 239MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  43%|██▏  | 1.65G/3.86G [00:07<00:09, 239MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  43%|██▏  | 1.68G/3.86G [00:07<00:09, 235MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  44%|██▏  | 1.71G/3.86G [00:07<00:09, 239MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  45%|██▎  | 1.74G/3.86G [00:07<00:08, 240MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  46%|██▎  | 1.77G/3.86G [00:07<00:08, 238MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  47%|██▎  | 1.80G/3.86G [00:07<00:09, 226MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  47%|██▎  | 1.84G/3.86G [00:07<00:08, 232MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  48%|██▍  | 1.87G/3.86G [00:08<00:08, 234MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  49%|██▍  | 1.90G/3.86G [00:08<00:09, 201MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  50%|██▍  | 1.93G/3.86G [00:08<00:09, 211MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  51%|██▌  | 1.96G/3.86G [00:08<00:08, 220MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  52%|██▌  | 1.99G/3.86G [00:08<00:08, 226MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  52%|██▌  | 2.02G/3.86G [00:08<00:08, 228MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  53%|██▋  | 2.06G/3.86G [00:08<00:07, 234MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  54%|██▋  | 2.09G/3.86G [00:09<00:07, 235MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  55%|██▋  | 2.12G/3.86G [00:09<00:09, 184MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  56%|██▊  | 2.15G/3.86G [00:09<00:08, 199MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  56%|██▊  | 2.18G/3.86G [00:09<00:08, 210MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  57%|██▊  | 2.21G/3.86G [00:09<00:07, 217MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  58%|██▉  | 2.24G/3.86G [00:09<00:07, 225MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  59%|██▉  | 2.28G/3.86G [00:09<00:06, 235MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  60%|██▉  | 2.31G/3.86G [00:10<00:08, 179MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  60%|███  | 2.33G/3.86G [00:10<00:08, 176MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  61%|███  | 2.35G/3.86G [00:10<00:08, 182MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  62%|███  | 2.38G/3.86G [00:10<00:07, 198MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  62%|███  | 2.41G/3.86G [00:10<00:06, 211MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  63%|███▏ | 2.44G/3.86G [00:10<00:06, 221MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  64%|███▏ | 2.47G/3.86G [00:10<00:06, 226MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  65%|███▏ | 2.51G/3.86G [00:11<00:05, 227MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  66%|███▎ | 2.54G/3.86G [00:11<00:06, 201MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  66%|███▎ | 2.57G/3.86G [00:11<00:06, 213MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  67%|███▎ | 2.60G/3.86G [00:11<00:05, 219MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  68%|███▍ | 2.63G/3.86G [00:11<00:05, 219MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  69%|███▍ | 2.66G/3.86G [00:11<00:05, 225MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  70%|███▍ | 2.69G/3.86G [00:11<00:05, 229MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  71%|███▌ | 2.73G/3.86G [00:12<00:06, 185MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  71%|███▌ | 2.76G/3.86G [00:12<00:05, 201MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  72%|███▌ | 2.79G/3.86G [00:12<00:05, 214MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  73%|███▋ | 2.82G/3.86G [00:12<00:04, 220MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  74%|███▋ | 2.85G/3.86G [00:12<00:04, 230MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  75%|███▋ | 2.88G/3.86G [00:12<00:04, 233MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  75%|███▊ | 2.92G/3.86G [00:12<00:04, 235MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  76%|███▊ | 2.95G/3.86G [00:13<00:05, 178MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  77%|███▊ | 2.98G/3.86G [00:13<00:04, 195MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  78%|███▉ | 3.01G/3.86G [00:13<00:04, 212MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  79%|███▉ | 3.04G/3.86G [00:13<00:03, 220MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  79%|███▉ | 3.07G/3.86G [00:13<00:03, 223MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  80%|████ | 3.10G/3.86G [00:13<00:03, 228MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  81%|████ | 3.14G/3.86G [00:14<00:03, 233MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  82%|████ | 3.17G/3.86G [00:14<00:04, 167MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  83%|████▏| 3.20G/3.86G [00:14<00:03, 184MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  84%|████▏| 3.23G/3.86G [00:14<00:03, 199MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  84%|████▏| 3.26G/3.86G [00:14<00:02, 211MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  85%|████▎| 3.29G/3.86G [00:14<00:02, 219MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  86%|████▎| 3.32G/3.86G [00:15<00:02, 226MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  87%|████▎| 3.36G/3.86G [00:15<00:02, 190MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  88%|████▍| 3.39G/3.86G [00:15<00:02, 207MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  88%|████▍| 3.42G/3.86G [00:15<00:02, 204MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  89%|████▍| 3.45G/3.86G [00:15<00:01, 218MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  90%|████▌| 3.48G/3.86G [00:15<00:01, 224MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  91%|████▌| 3.51G/3.86G [00:15<00:01, 227MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  92%|████▌| 3.54G/3.86G [00:16<00:01, 232MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  93%|████▋| 3.58G/3.86G [00:16<00:01, 186MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  93%|████▋| 3.61G/3.86G [00:16<00:01, 201MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  94%|████▋| 3.64G/3.86G [00:16<00:01, 214MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  95%|████▋| 3.67G/3.86G [00:16<00:00, 222MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  96%|████▊| 3.70G/3.86G [00:16<00:00, 229MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  97%|████▊| 3.73G/3.86G [00:16<00:00, 234MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  97%|████▊| 3.76G/3.86G [00:17<00:00, 236MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  98%|████▉| 3.80G/3.86G [00:17<00:00, 178MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  99%|████▉| 3.83G/3.86G [00:17<00:00, 193MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors: 100%|█████| 3.86G/3.86G [00:17<00:00, 220MB/s]\u001b[A\n",
      "Downloading shards:  50%|████████████▌            | 2/4 [00:36<00:35, 17.98s/it]\n",
      "model-00003-of-00004.safetensors:   0%|             | 0.00/3.86G [00:00<?, ?B/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   1%|     | 31.5M/3.86G [00:00<00:15, 240MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   2%|     | 62.9M/3.86G [00:00<00:15, 242MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   2%|     | 94.4M/3.86G [00:00<00:15, 241MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   3%|▏     | 126M/3.86G [00:00<00:15, 243MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   4%|▏     | 157M/3.86G [00:00<00:15, 246MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   5%|▎     | 189M/3.86G [00:00<00:15, 238MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   6%|▎     | 220M/3.86G [00:00<00:15, 238MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   7%|▍     | 252M/3.86G [00:01<00:14, 243MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   7%|▍     | 283M/3.86G [00:01<00:14, 250MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   8%|▍     | 315M/3.86G [00:01<00:14, 246MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   9%|▌     | 346M/3.86G [00:01<00:14, 244MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  10%|▌     | 377M/3.86G [00:01<00:14, 241MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  11%|▋     | 409M/3.86G [00:01<00:14, 244MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  11%|▋     | 440M/3.86G [00:01<00:14, 243MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  12%|▋     | 472M/3.86G [00:01<00:14, 241MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  13%|▊     | 503M/3.86G [00:02<00:13, 251MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  14%|▊     | 535M/3.86G [00:02<00:13, 250MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  15%|▉     | 566M/3.86G [00:02<00:13, 251MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  15%|▉     | 598M/3.86G [00:02<00:13, 250MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  16%|▉     | 629M/3.86G [00:02<00:13, 247MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  17%|█     | 661M/3.86G [00:02<00:12, 249MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  18%|█     | 692M/3.86G [00:02<00:12, 251MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  19%|█     | 724M/3.86G [00:02<00:12, 250MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  20%|█▏    | 755M/3.86G [00:03<00:12, 246MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  20%|█▏    | 786M/3.86G [00:03<00:12, 244MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  21%|█▎    | 818M/3.86G [00:03<00:14, 215MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  22%|█▎    | 849M/3.86G [00:03<00:16, 188MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  23%|█▎    | 881M/3.86G [00:03<00:14, 205MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  24%|█▍    | 912M/3.86G [00:03<00:13, 213MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  24%|█▍    | 944M/3.86G [00:03<00:13, 224MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  25%|█▌    | 975M/3.86G [00:04<00:12, 229MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  26%|█▎   | 1.01G/3.86G [00:04<00:11, 239MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  27%|█▎   | 1.04G/3.86G [00:04<00:11, 239MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  28%|█▍   | 1.07G/3.86G [00:04<00:15, 179MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  28%|█▍   | 1.10G/3.86G [00:04<00:14, 194MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  29%|█▍   | 1.13G/3.86G [00:04<00:13, 210MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  30%|█▌   | 1.16G/3.86G [00:05<00:12, 221MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  31%|█▌   | 1.20G/3.86G [00:05<00:11, 227MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  32%|█▌   | 1.23G/3.86G [00:05<00:11, 233MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  33%|█▋   | 1.26G/3.86G [00:05<00:14, 174MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  33%|█▋   | 1.29G/3.86G [00:05<00:13, 188MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  34%|█▋   | 1.32G/3.86G [00:05<00:12, 202MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  35%|█▊   | 1.35G/3.86G [00:05<00:12, 207MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  36%|█▊   | 1.38G/3.86G [00:06<00:11, 222MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  37%|█▊   | 1.42G/3.86G [00:06<00:10, 229MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  37%|█▊   | 1.45G/3.86G [00:06<00:10, 238MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  38%|█▉   | 1.48G/3.86G [00:06<00:13, 182MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  39%|█▉   | 1.51G/3.86G [00:06<00:11, 197MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  40%|█▉   | 1.54G/3.86G [00:06<00:11, 209MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  41%|██   | 1.57G/3.86G [00:07<00:10, 216MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  42%|██   | 1.60G/3.86G [00:07<00:10, 224MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  42%|██   | 1.64G/3.86G [00:07<00:09, 230MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  43%|██▏  | 1.67G/3.86G [00:07<00:09, 236MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  44%|██▏  | 1.70G/3.86G [00:07<00:12, 178MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  45%|██▏  | 1.73G/3.86G [00:07<00:10, 194MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  46%|██▎  | 1.76G/3.86G [00:07<00:09, 212MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  46%|██▎  | 1.79G/3.86G [00:08<00:09, 221MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  47%|██▎  | 1.82G/3.86G [00:08<00:09, 221MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  48%|██▍  | 1.86G/3.86G [00:08<00:08, 226MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  49%|██▍  | 1.89G/3.86G [00:08<00:11, 179MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  50%|██▍  | 1.92G/3.86G [00:08<00:10, 192MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  50%|██▌  | 1.95G/3.86G [00:08<00:09, 204MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  51%|██▌  | 1.98G/3.86G [00:08<00:08, 212MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  52%|██▌  | 2.01G/3.86G [00:09<00:11, 160MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  53%|██▋  | 2.04G/3.86G [00:09<00:10, 181MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  54%|██▋  | 2.08G/3.86G [00:09<00:09, 194MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  55%|██▋  | 2.11G/3.86G [00:09<00:08, 206MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  55%|██▊  | 2.14G/3.86G [00:09<00:07, 216MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  56%|██▊  | 2.17G/3.86G [00:09<00:07, 220MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  57%|██▊  | 2.20G/3.86G [00:10<00:07, 225MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  58%|██▉  | 2.23G/3.86G [00:10<00:07, 223MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  59%|██▉  | 2.26G/3.86G [00:10<00:06, 230MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  59%|██▉  | 2.30G/3.86G [00:10<00:06, 229MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  60%|███  | 2.33G/3.86G [00:10<00:07, 208MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  61%|███  | 2.36G/3.86G [00:10<00:06, 225MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  62%|███  | 2.39G/3.86G [00:10<00:06, 228MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  63%|███▏ | 2.42G/3.86G [00:11<00:06, 228MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  63%|███▏ | 2.45G/3.86G [00:11<00:06, 228MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  64%|███▏ | 2.49G/3.86G [00:11<00:06, 230MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  65%|███▎ | 2.52G/3.86G [00:11<00:07, 183MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  66%|███▎ | 2.55G/3.86G [00:11<00:06, 195MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  67%|███▎ | 2.58G/3.86G [00:11<00:06, 205MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  68%|███▍ | 2.61G/3.86G [00:11<00:05, 217MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  68%|███▍ | 2.64G/3.86G [00:12<00:05, 225MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  69%|███▍ | 2.67G/3.86G [00:12<00:05, 228MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  70%|███▌ | 2.71G/3.86G [00:12<00:05, 232MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  71%|███▌ | 2.74G/3.86G [00:12<00:06, 184MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  72%|███▌ | 2.77G/3.86G [00:12<00:05, 195MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  72%|███▌ | 2.80G/3.86G [00:12<00:05, 207MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  73%|███▋ | 2.83G/3.86G [00:13<00:04, 214MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  74%|███▋ | 2.86G/3.86G [00:13<00:04, 220MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  75%|███▋ | 2.89G/3.86G [00:13<00:04, 229MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  76%|███▊ | 2.93G/3.86G [00:13<00:04, 209MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  77%|███▊ | 2.96G/3.86G [00:13<00:04, 190MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  77%|███▊ | 2.99G/3.86G [00:13<00:04, 200MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  78%|███▉ | 3.02G/3.86G [00:13<00:04, 209MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  79%|███▉ | 3.05G/3.86G [00:14<00:03, 217MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  80%|███▉ | 3.08G/3.86G [00:14<00:03, 222MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  81%|████ | 3.11G/3.86G [00:14<00:03, 225MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  81%|████ | 3.15G/3.86G [00:14<00:03, 185MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  82%|████ | 3.18G/3.86G [00:14<00:03, 199MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  83%|████▏| 3.21G/3.86G [00:14<00:03, 209MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  84%|████▏| 3.24G/3.86G [00:14<00:02, 213MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  85%|████▏| 3.27G/3.86G [00:15<00:02, 231MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  85%|████▎| 3.30G/3.86G [00:15<00:02, 233MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  86%|████▎| 3.33G/3.86G [00:15<00:02, 234MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  87%|████▎| 3.37G/3.86G [00:15<00:02, 182MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  88%|████▍| 3.40G/3.86G [00:15<00:02, 197MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  89%|████▍| 3.43G/3.86G [00:15<00:02, 208MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  90%|████▍| 3.46G/3.86G [00:16<00:01, 216MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  90%|████▌| 3.49G/3.86G [00:16<00:01, 222MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  91%|████▌| 3.52G/3.86G [00:16<00:01, 229MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  92%|████▌| 3.55G/3.86G [00:16<00:01, 230MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  93%|████▋| 3.59G/3.86G [00:16<00:01, 188MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  94%|████▋| 3.62G/3.86G [00:16<00:01, 201MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  94%|████▋| 3.65G/3.86G [00:16<00:01, 212MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  95%|████▊| 3.68G/3.86G [00:17<00:00, 190MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  96%|████▊| 3.70G/3.86G [00:17<00:00, 194MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  97%|████▊| 3.73G/3.86G [00:17<00:00, 205MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  97%|████▊| 3.76G/3.86G [00:17<00:00, 225MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  98%|████▉| 3.80G/3.86G [00:17<00:00, 195MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  99%|████▉| 3.83G/3.86G [00:17<00:00, 211MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors: 100%|█████| 3.86G/3.86G [00:17<00:00, 215MB/s]\u001b[A\n",
      "Downloading shards:  75%|██████████████████▊      | 3/4 [00:54<00:17, 17.99s/it]\n",
      "model-00004-of-00004.safetensors:   0%|             | 0.00/3.56G [00:00<?, ?B/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   1%|     | 21.0M/3.56G [00:00<00:24, 143MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   1%|     | 52.4M/3.56G [00:00<00:18, 190MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   2%|     | 83.9M/3.56G [00:00<00:16, 211MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   3%|▏     | 115M/3.56G [00:00<00:15, 224MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   4%|▏     | 147M/3.56G [00:00<00:14, 228MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   5%|▎     | 178M/3.56G [00:00<00:14, 233MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   6%|▎     | 210M/3.56G [00:00<00:14, 232MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   7%|▍     | 241M/3.56G [00:01<00:14, 231MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   8%|▍     | 273M/3.56G [00:01<00:14, 234MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   9%|▌     | 304M/3.56G [00:01<00:13, 235MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   9%|▌     | 336M/3.56G [00:01<00:13, 238MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  10%|▌     | 367M/3.56G [00:01<00:13, 239MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  11%|▋     | 398M/3.56G [00:01<00:13, 240MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  12%|▋     | 430M/3.56G [00:01<00:13, 231MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  13%|▊     | 461M/3.56G [00:02<00:13, 231MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  14%|▊     | 493M/3.56G [00:02<00:13, 234MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  15%|▉     | 524M/3.56G [00:02<00:12, 236MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  16%|▉     | 556M/3.56G [00:02<00:12, 233MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  17%|▉     | 587M/3.56G [00:02<00:12, 235MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  17%|█     | 619M/3.56G [00:02<00:12, 235MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  18%|█     | 650M/3.56G [00:02<00:12, 233MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  19%|█▏    | 682M/3.56G [00:02<00:12, 235MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  20%|█▏    | 713M/3.56G [00:03<00:11, 238MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  21%|█▎    | 744M/3.56G [00:03<00:11, 240MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  22%|█▎    | 776M/3.56G [00:03<00:11, 244MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  23%|█▎    | 807M/3.56G [00:03<00:11, 240MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  24%|█▍    | 839M/3.56G [00:03<00:11, 246MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  24%|█▍    | 870M/3.56G [00:03<00:10, 245MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  25%|█▌    | 902M/3.56G [00:03<00:11, 241MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  26%|█▌    | 933M/3.56G [00:03<00:10, 240MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  27%|█▋    | 965M/3.56G [00:04<00:10, 239MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  28%|█▋    | 996M/3.56G [00:04<00:10, 235MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  29%|█▍   | 1.03G/3.56G [00:04<00:10, 237MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  30%|█▍   | 1.06G/3.56G [00:04<00:12, 200MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  31%|█▌   | 1.09G/3.56G [00:04<00:11, 207MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  32%|█▌   | 1.12G/3.56G [00:04<00:11, 215MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  32%|█▌   | 1.15G/3.56G [00:05<00:10, 221MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  33%|█▋   | 1.18G/3.56G [00:05<00:10, 227MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  34%|█▋   | 1.22G/3.56G [00:05<00:10, 228MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  35%|█▊   | 1.25G/3.56G [00:05<00:09, 233MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  36%|█▊   | 1.28G/3.56G [00:05<00:12, 188MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  37%|█▊   | 1.31G/3.56G [00:05<00:11, 203MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  38%|█▉   | 1.34G/3.56G [00:05<00:10, 212MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  39%|█▉   | 1.37G/3.56G [00:06<00:09, 221MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  40%|█▉   | 1.41G/3.56G [00:06<00:09, 221MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  40%|██   | 1.44G/3.56G [00:06<00:09, 232MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  41%|██   | 1.47G/3.56G [00:06<00:11, 181MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  42%|██   | 1.50G/3.56G [00:06<00:10, 195MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  43%|██▏  | 1.53G/3.56G [00:06<00:09, 206MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  44%|██▏  | 1.56G/3.56G [00:06<00:09, 216MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  45%|██▏  | 1.59G/3.56G [00:07<00:08, 223MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  46%|██▎  | 1.63G/3.56G [00:07<00:08, 222MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  47%|██▎  | 1.66G/3.56G [00:07<00:08, 216MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  47%|██▎  | 1.69G/3.56G [00:07<00:10, 187MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  48%|██▍  | 1.72G/3.56G [00:07<00:09, 196MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  49%|██▍  | 1.75G/3.56G [00:07<00:08, 208MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  50%|██▌  | 1.78G/3.56G [00:08<00:08, 218MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  51%|██▌  | 1.81G/3.56G [00:08<00:07, 223MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  52%|██▌  | 1.85G/3.56G [00:08<00:08, 213MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  53%|██▋  | 1.88G/3.56G [00:08<00:07, 220MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  54%|██▋  | 1.91G/3.56G [00:08<00:08, 193MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  55%|██▋  | 1.94G/3.56G [00:08<00:07, 206MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  55%|██▊  | 1.97G/3.56G [00:08<00:07, 218MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  56%|██▊  | 2.00G/3.56G [00:09<00:06, 223MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  57%|██▊  | 2.03G/3.56G [00:09<00:06, 228MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  58%|██▉  | 2.07G/3.56G [00:09<00:06, 231MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  59%|██▉  | 2.10G/3.56G [00:09<00:08, 179MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  60%|██▉  | 2.13G/3.56G [00:09<00:07, 198MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  61%|███  | 2.16G/3.56G [00:09<00:06, 207MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  62%|███  | 2.19G/3.56G [00:09<00:06, 218MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  63%|███▏ | 2.22G/3.56G [00:10<00:05, 224MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  63%|███▏ | 2.25G/3.56G [00:10<00:05, 229MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  64%|███▏ | 2.29G/3.56G [00:10<00:05, 233MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  65%|███▎ | 2.32G/3.56G [00:10<00:06, 180MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  66%|███▎ | 2.35G/3.56G [00:10<00:06, 195MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  67%|███▎ | 2.38G/3.56G [00:10<00:05, 211MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  68%|███▍ | 2.41G/3.56G [00:10<00:05, 216MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  69%|███▍ | 2.44G/3.56G [00:11<00:05, 223MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  70%|███▍ | 2.47G/3.56G [00:11<00:04, 229MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  70%|███▌ | 2.51G/3.56G [00:11<00:04, 233MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  71%|███▌ | 2.54G/3.56G [00:11<00:05, 180MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  72%|███▌ | 2.57G/3.56G [00:11<00:05, 194MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  73%|███▋ | 2.60G/3.56G [00:11<00:04, 204MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  74%|███▋ | 2.63G/3.56G [00:12<00:04, 212MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  75%|███▋ | 2.66G/3.56G [00:12<00:04, 222MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  76%|███▊ | 2.69G/3.56G [00:12<00:03, 228MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  77%|███▊ | 2.73G/3.56G [00:12<00:04, 181MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  78%|███▉ | 2.76G/3.56G [00:12<00:04, 199MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  78%|███▉ | 2.79G/3.56G [00:12<00:03, 208MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  79%|███▉ | 2.82G/3.56G [00:12<00:03, 216MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  80%|████ | 2.85G/3.56G [00:13<00:03, 222MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  81%|████ | 2.88G/3.56G [00:13<00:02, 231MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  82%|████ | 2.92G/3.56G [00:13<00:02, 217MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  83%|████▏| 2.95G/3.56G [00:13<00:03, 184MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  84%|████▏| 2.98G/3.56G [00:13<00:02, 195MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  85%|████▏| 3.01G/3.56G [00:13<00:02, 208MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  86%|████▎| 3.04G/3.56G [00:14<00:02, 215MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  86%|████▎| 3.07G/3.56G [00:14<00:02, 223MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  87%|████▎| 3.10G/3.56G [00:14<00:01, 230MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  88%|████▍| 3.14G/3.56G [00:14<00:01, 229MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  89%|████▍| 3.17G/3.56G [00:14<00:02, 183MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  90%|████▍| 3.20G/3.56G [00:14<00:01, 198MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  91%|████▌| 3.23G/3.56G [00:14<00:01, 209MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  92%|████▌| 3.26G/3.56G [00:15<00:01, 219MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  93%|████▋| 3.29G/3.56G [00:15<00:01, 223MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  93%|████▋| 3.32G/3.56G [00:15<00:01, 228MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  94%|████▋| 3.36G/3.56G [00:15<00:01, 182MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  95%|████▊| 3.39G/3.56G [00:15<00:00, 196MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  96%|████▊| 3.42G/3.56G [00:15<00:00, 207MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  97%|████▊| 3.45G/3.56G [00:15<00:00, 218MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  98%|████▉| 3.48G/3.56G [00:16<00:00, 225MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  99%|████▉| 3.51G/3.56G [00:16<00:00, 220MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors: 100%|█████| 3.56G/3.56G [00:16<00:00, 217MB/s]\u001b[A\n",
      "Downloading shards: 100%|█████████████████████████| 4/4 [01:10<00:00, 17.65s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:17<00:00,  4.27s/it]\n",
      "generation_config.json: 100%|██████████████████| 243/243 [00:00<00:00, 4.65MB/s]\n",
      "Loading PEFT: ./qwen2.5-7b-functioncall/checkpoint-500\n",
      "Running merge_and_unload\n",
      "tokenizer_config.json: 100%|███████████████| 7.30k/7.30k [00:00<00:00, 57.3MB/s]\n",
      "vocab.json: 100%|██████████████████████████| 2.78M/2.78M [00:00<00:00, 16.6MB/s]\n",
      "merges.txt: 100%|██████████████████████████| 1.67M/1.67M [00:00<00:00, 12.8MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 7.03M/7.03M [00:00<00:00, 10.4MB/s]\n",
      "Model saved to ./output_dir\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import  AutoTokenizer, pipeline\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "peft_model_id = \"qwen2.5-7b-functioncall/checkpoint-500\"\n",
    "\n",
    "!python merge.py \\\n",
    "    --base_model_name_or_path Qwen/Qwen2.5-7B-Instruct \\\n",
    "    --peft_model_path ./qwen2.5-7b-functioncall/checkpoint-500 \\\n",
    "    --output_dir ./output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c9a8bd-e7e8-4b59-b7d3-ca2e9e6498f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Invalid requirement: '==2.5.8'\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install flash_attn ==2.5.8 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f47877e8-888a-4019-919e-d60ed9c3964c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566d2e11314d493e8abb094a636da77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./output_dir')\n",
    "model = AutoModelForCausalLM.from_pretrained('./output_dir')\n",
    "model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e5c2e4-9c03-4e5a-bdc5-1db31c594d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\":system_prompt +'오늘 날짜는 2025-03-09 입니다.'},\n",
    "    {\"role\": \"user\", \"content\": \"테슬라의 최근 성장률은 어때?\"}\n",
    "]\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "model_inputs = encodeds.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ac9e48a-b063-4917-9356-1ca1ac3413b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = tokenizer.decode(model_inputs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7403a237-7db8-4337-b5c3-e7e9f9457c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "당신은 다양한 기능을 호출할 수 있는 AI 모델입니다. 사용자의 요청에 따라 특정 함수를 호출하고, 함수의 시그니처는 <tools></tools> XML 태그 내에 제공됩니다. 함수를 호출할 때는 함수에 필요한 정확한 값을 추정하지 말고 사용자가 제공한 값에 따라 함수를 실행해야 합니다.\n",
      "\n",
      "아래는 사용 가능한 함수들과 각각의 파라미터에 대한 설명입니다:\n",
      "\n",
      "get_issues_summarized\n",
      "\n",
      "설명: 특정 회사 또는 키워드에 대한 이슈를 검색하고 요약합니다.\n",
      "파라미터:\n",
      "keyword: 이슈/현황을 검색하고자 하는 회사명 또는 키워드.\n",
      "days: 검색하고자 하는 기간(일 단위 (integer)).\n",
      "\n",
      "get_reddit_hotissue\n",
      "\n",
      "설명: 금융시장에서 핫한 이슈를 요약합니다.\n",
      "파라미터:\n",
      "days: 검색하고자 하는 기간(일 단위).\n",
      "\n",
      "{name: get_earnings,\n",
      "설명: 기업의 재무재표 또는 현금흐름을 가져오고 분석합니다. 성장률과 같이 이전 년도 데이터가 필요한경우, 이전 년도 데이터도 한번 더 호출하세요\n",
      "파라미터:{symbol: 실적 데이터를 찾고자 하는 기업의 심볼.\n",
      "analysis_type: 분석 유형(growth, profitability, stability, valuation, cashflow, dividend, cost, NA).\n",
      "type_: 데이터 타입(yearly 또는 quarter).\n",
      "year: 데이터를 찾고자 하는 연도 (명시하지 않을경우, 데이터가 존재하는 최근 연도의 데이터를 참조합니다.).\n",
      "quarter: 데이터를 찾고자 하는 분기(명시하지않은 경우 최근 데이터를 조회하도록 -1 을 입력합니다).}}\n",
      "\n",
      "get_consensus\n",
      "\n",
      "설명: 기업의 EPS 컨센서스 데이터 또는 매수/매도/홀드 의견을 가져와서 분석합니다.\n",
      "파라미터:\n",
      "symbol: 데이터를 찾고자 하는 기업의 심볼.\n",
      "year: 데이터를 찾고자 하는 연도.\n",
      "quarter: 데이터를 찾고자 하는 분기.\n",
      "각 함수 호출 시, JSON 객체를 사용하여 함수 이름과 인자들을 <tool_call></tool_call> XML 태그 내에 명시해야 합니다. 함수 호출 예시는 다음과 같습니다:\n",
      "\n",
      "xml\n",
      "Copy\n",
      "<tool_call>\n",
      "{\n",
      "    \"name\": \"get_earnings\",\n",
      "    \"arguments\": {\n",
      "        \"symbol\": \"AAPL\",\n",
      "        \"analysis_type\": \"growth\",\n",
      "        \"type_\": \"yearly\" ,\n",
      "        \"year\": \"2024\",\n",
      "        \"quarter\": \"-1\"\n",
      "    }\n",
      "}\n",
      "</tool_call>\n",
      "각 함수의 인자 값을 정확하게 지정해 주세요. 특히, 연도와 분기를 설정할 때 현재 날짜가 1월이나 2월인 경우, 최근 연도의 데이터를 참조하도록 주의해야 합니다.\n",
      "**주의사항\n",
      "함수를 호출할때를 제외하고 한국어로 대답하세요.\n",
      "\n",
      "오늘 날짜는 2025-03-09 입니다.<|im_end|>\n",
      "<|im_start|>user\n",
      "테슬라의 최근 성장률은 어때?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>{\"name\":\"get_earnings\",\"arguments\": {\"symbol\": \"TSLA\", \"analysis_type\": \"growth\", \"type_\": \"yearly\", \"year\": \"2024\", \"quarter\": \"-1\"}}</tool_call><|im_end|>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "eos_token_id = tokenizer.convert_tokens_to_ids(\"<|im_end|>\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.module.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=2048, eos_token_id=eos_token_id)\n",
    "    print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38a0a125-cb6f-4eea-ae00-4e7e6aa1ca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: huggingface-cli <command> [<args>]\n",
      "huggingface-cli: error: unrecognized arguments: —token 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\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login —token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7eb6a32-509e-429e-9b94-b2c4f5cefe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "username = \"irene93\"\n",
    "\n",
    "MODEL_NAME = 'functioncall_stkissue'\n",
    "token ='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aab35e9c-079b-4dea-98da-81b8622270ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4867de9db1de403db85bf57952e806f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2cecf30cd149da8616da13ffc2ca7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb9b29104da4a26bcfde517ab671069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f57aae4977d40c1bae705939e129a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45cc31f850442fd966152de3abf302f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f2932cfff149308ccaced7f3caa99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/irene93/functioncall_stkissue/commit/cd9c86a33b90beb525ac097aa1a077087db69851', commit_message='Upload folder using huggingface_hub', commit_description='', oid='cd9c86a33b90beb525ac097aa1a077087db69851', pr_url=None, repo_url=RepoUrl('https://huggingface.co/irene93/functioncall_stkissue', endpoint='https://huggingface.co', repo_type='model', repo_id='irene93/functioncall_stkissue'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.create_repo(\n",
    "    token=token, ### 토큰값 ,\n",
    "    repo_id=f\"{username}/{MODEL_NAME}\",\n",
    "    repo_type=\"model\"\n",
    ")\n",
    "\n",
    "api.upload_folder(\n",
    "    token=token,### 토큰값 ,\n",
    "    repo_id=f\"{username}/{MODEL_NAME}\",\n",
    "    folder_path=\"output_dir\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc5823-35d1-48c9-acdc-bde2e302e642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
